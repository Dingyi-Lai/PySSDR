{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip show tensorflow numpy keras\n",
    "# !pip install pillow\n",
    "!pip install .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-05 10:04:50.769611: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-05 10:04:51.044669: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/scc/pa6512/miniconda3/lib/python3.12/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "# from sklearn.gaussian_process.kernels import RBF\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras import Input, Model\n",
    "from keras.models import load_model, Sequential\n",
    "from keras.layers import Dense, Flatten, ReLU\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from time import time\n",
    "from scipy.stats import poisson, gamma, norm\n",
    "from scipy.optimize import minimize_scalar\n",
    "import multiprocessing as mp\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# from sddr import Sddr  # Assuming you have pyssdr installed and configured correctly\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from itertools import product\n",
    "\n",
    "# import torch\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "import os\n",
    "import sys\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "# import the sddr module\n",
    "from sddr import Sddr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scale_to_range(data, lower=-1, upper=1):\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data)) * (upper - lower) + lower\n",
    "\n",
    "def save_with_var_name(var, var_name, var_type, save_path, scenario_index):\n",
    "    if var_type == 'npy':\n",
    "        np.save(f\"{save_path}/{var_name}_{scenario_index}.npy\", var)\n",
    "    if var_type == 'keras':\n",
    "        var.save(f\"{save_path}/{var_name}_{scenario_index}.keras\")\n",
    "    if var_type == 'jpgs':\n",
    "        images_path = f\"{save_path}/{var_name}_{scenario_index}\"\n",
    "        os.makedirs(images_path, exist_ok=True)\n",
    "        for idx, img in enumerate(var):\n",
    "            # Normalize and convert to uint8\n",
    "            normalized_img = (img * 255 / np.max(img)).astype(np.uint8)\n",
    "            # Convert the NumPy array to an image\n",
    "            normalized_img = Image.fromarray(normalized_img).convert(\"L\")\n",
    "            normalized_img.save(f\"{images_path}/{var_name}_{scenario_index}_{idx}.jpg\")\n",
    "    if var_type == 'pth':\n",
    "        var.save(f\"{var_name}_{scenario_index}.pth\")\n",
    "    if var_type == 'df':\n",
    "        var.to_csv(f\"{save_path}/{var_name}_{scenario_index}.csv\", index=False)\n",
    "\n",
    "    logging.info(f\"Saved {var_name} to {save_path}/{var_name}_{scenario_index}.npy\")\n",
    "    \n",
    "def read_with_var_name(var_name, var_type, save_path, scenario_index):\n",
    "    if var_type == 'npy':\n",
    "        return np.load(f\"{save_path}/{var_name}_{scenario_index}.npy\")\n",
    "    if var_type == 'keras':\n",
    "        return tf.keras.models.load_model(f\"{save_path}/{var_name}_{scenario_index}.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_path = \"../data_generation/output_linear\"\n",
    "scenario_index = f\"n_{1000}_rep_{0}\"\n",
    "# U_k = read_with_var_name('U_k', 'npy', read_path, scenario_index)\n",
    "output_dimension_dnn = 16\n",
    "save_path = \"./outputs_wo_unstructured_nknots_16_batch_32\"\n",
    "X = read_with_var_name('X', 'npy', read_path, scenario_index)\n",
    "# linear_effects = read_with_var_name('linear_effects', 'npy', read_path, scenario_index)\n",
    "# print(X.shape)\n",
    "Z = read_with_var_name('Z', 'npy', read_path, scenario_index)\n",
    "nonlinear_effects = read_with_var_name('nonlinear_effects', 'npy', read_path, scenario_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_knots = 16\n",
    "grid_size = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scc/pa6512/miniconda3/lib/python3.12/site-packages/sddr/utils/utils.py:395: UserWarning: df too large: Degrees of freedom (df = 19) cannot be larger than the rank of the design matrix (rank = 18). \n",
      "            Unpenalized base-learner with df = 18 will be used. Re-consider model specification.\n",
      "  df_lam = df2lambda(dm_spline, P_val, df_val)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (0,) into shape (18,18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 70\u001b[0m\n\u001b[1;32m     68\u001b[0m y \u001b[38;5;241m=\u001b[39m read_with_var_name(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnpy\u001b[39m\u001b[38;5;124m'\u001b[39m, read_path, scenario_index)\n\u001b[1;32m     69\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m---> 70\u001b[0m ssdr\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./outputs_wo_unstructured_nknots_16_batch_32/ssdr_n_1000_rep_0_dist_gaussian_homo_SNR_1_point_estimates.pth\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     71\u001b[0m           df)\n\u001b[1;32m     72\u001b[0m ssdr\u001b[38;5;241m.\u001b[39mtrain(target\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m, structured_data\u001b[38;5;241m=\u001b[39mdf, resume\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/sddr/sddr.py:458\u001b[0m, in \u001b[0;36mSddr.load\u001b[0;34m(self, model_name, training_data)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_name, training_data):\n\u001b[0;32m--> 458\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_and_create_design_info(training_data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_data)\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mP \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_data\u001b[38;5;241m.\u001b[39mget_penalty_matrix(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/sddr/sddr.py:437\u001b[0m, in \u001b[0;36mSddr._load_and_create_design_info\u001b[0;34m(self, training_data, prepare_data)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(training_data, pd\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[1;32m    436\u001b[0m     training_data \u001b[38;5;241m=\u001b[39m training_data\n\u001b[0;32m--> 437\u001b[0m prepare_data\u001b[38;5;241m.\u001b[39mfit(training_data)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/sddr/utils/prepare_data.py:179\u001b[0m, in \u001b[0;36mPrepareData.fit\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstructured_matrix_design_info[param] \u001b[38;5;241m=\u001b[39m structured_matrix\u001b[38;5;241m.\u001b[39mdesign_info\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# Compute the penalty matrix and extract basis information.\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m big_P, basis_dict \u001b[38;5;241m=\u001b[39m get_P_from_design_matrix(structured_matrix, dfs)\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mP[param] \u001b[38;5;241m=\u001b[39m big_P\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbasis_info[param] \u001b[38;5;241m=\u001b[39m basis_dict  \u001b[38;5;66;03m# Store basis matrices for later reconstruction.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/sddr/utils/utils.py:397\u001b[0m, in \u001b[0;36mget_P_from_design_matrix\u001b[0;34m(dm, dfs)\u001b[0m\n\u001b[1;32m    395\u001b[0m df_lam \u001b[38;5;241m=\u001b[39m df2lambda(dm_spline, P_val, df_val)\n\u001b[1;32m    396\u001b[0m \u001b[38;5;66;03m# Fill the block in the overall penalty matrix.\u001b[39;00m\n\u001b[0;32m--> 397\u001b[0m big_P[slice_of_term, slice_of_term] \u001b[38;5;241m=\u001b[39m P_val \u001b[38;5;241m*\u001b[39m df_lam[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    398\u001b[0m \u001b[38;5;66;03m# Store the basis for this spline term.\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;66;03m# If basis_val is provided from the transform of the Spline object, use it;\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;66;03m# otherwise, use the corresponding columns of the design matrix.\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m basis_val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (0,) into shape (18,18)"
     ]
    }
   ],
   "source": [
    "distribution_SSDR = \"Normal\" # compatible form\n",
    "formulas = {\n",
    "'loc': f\"~ 1 + X1 + X2 + spline(Z1, bs='bs', df={num_knots+3}) + spline(Z2, bs='bs', df={num_knots+3})\",\n",
    "'scale': '~ 1'\n",
    "}\n",
    "degrees_of_freedom = {'loc':num_knots+3, 'scale':num_knots+3}\n",
    "deep_models_dict = {\n",
    "        'dnn': {\n",
    "            'model': \n",
    "                # nn.Sequential(\n",
    "                # nn.Flatten(1, -1),\n",
    "                # nn.Linear(grid_size*grid_size,output_dimension_dnn),\n",
    "                # nn.ReLU()\n",
    "                \n",
    "                nn.Sequential(\n",
    "                nn.Flatten(1, -1),\n",
    "                nn.Linear(grid_size*grid_size, 32, bias=False),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(32, 16),\n",
    "                nn.ReLU(),\n",
    "                # nn.Linear(16, 1)\n",
    "                ),\n",
    "            \n",
    "            'output_shape': output_dimension_dnn},\n",
    "    }\n",
    "train_parameters = {\n",
    "        'batch_size': 32,              # Smaller batch size due to limited sample size.\n",
    "        'epochs': 100,\n",
    "        # 'degrees_of_freedom': {'rate': 3},  # For Poisson; adjust accordingly for other distributions.\n",
    "        'optimizer': optim.Adam,\n",
    "        'val_split': 0.15,             # Possibly a higher split for very small samples.\n",
    "        'early_stop_epsilon': 0.001,\n",
    "        # 'dropout_rate': 0.01           # Start with 0.01; consider 0.01-0.05 range.\n",
    "    }\n",
    "\n",
    "train_parameters['degrees_of_freedom'] = degrees_of_freedom\n",
    "unstructured_data = {\n",
    "    'Image' : {\n",
    "        'path' : f\"{read_path}/images_jpg_{scenario_index}/\",\n",
    "        'datatype' : 'image'\n",
    "    }\n",
    "    }\n",
    "ssdr = Sddr(output_dir=save_path,\n",
    "            distribution=distribution_SSDR,\n",
    "            formulas=formulas,\n",
    "            deep_models_dict=deep_models_dict,\n",
    "            train_parameters=train_parameters,\n",
    "            modify=True,\n",
    "            ortho_manual = True,\n",
    "            use_spline_for_struct = False,\n",
    "            n_knots = num_knots\n",
    "            )\n",
    "\n",
    "# print(Z.shape)\n",
    "# Step 1: Transpose X and Z\n",
    "X_transposed = X.T  # Shape (10, 2)\n",
    "Z_transposed = Z.T  # Shape (10, 2)\n",
    "\n",
    "# Step 2: Combine X and Z\n",
    "combined_data = np.hstack((X_transposed, Z_transposed))  # Shape (10, 4)\n",
    "df = pd.DataFrame(combined_data, columns=['X1', 'X2', 'Z1', 'Z2'])\n",
    "# df['Image'] = [f'images_jpg_{scenario_index}_{i}.jpg' for i in range(len(df))]\n",
    "# os.makedirs(save_path, exist_ok=True)\n",
    "scenario_index = scenario_index + f\"_dist_gaussian_homo_SNR_1\"\n",
    "\n",
    "# a = read_with_var_name('a', 'npy', save_path, scenario_index)\n",
    "# etas = read_with_var_name('etas', 'npy', save_path, scenario_index)\n",
    "y = read_with_var_name('y', 'npy', read_path, scenario_index)\n",
    "df['Y'] = y\n",
    "ssdr.load('./outputs_wo_unstructured_nknots_16_batch_32/ssdr_n_1000_rep_0_dist_gaussian_homo_SNR_1_point_estimates.pth',\n",
    "          df)\n",
    "ssdr.train(target=\"Y\", structured_data=df, resume=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ssdr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ssdr\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ssdr' is not defined"
     ]
    }
   ],
   "source": [
    "ssdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_loc = ssdr.net.single_parameter_sddr_list['loc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "spline_info = ssdr.prepare_data.dm_info_dict['loc']['spline_info']\n",
    "non_spline_info = ssdr.prepare_data.dm_info_dict['loc']['non_spline_info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'list_of_non_spline_slices': [slice(0, 1, None),\n",
       "  slice(1, 2, None),\n",
       "  slice(2, 3, None)],\n",
       " 'list_of_non_spline_input_features': [[], ['X1'], ['X2']],\n",
       " 'list_of_term_names': ['Intercept', 'X1', 'X2']}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_spline_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Intercept': array([0.06083461], dtype=float32),\n",
       " 'X1': array([-0.27388215], dtype=float32),\n",
       " 'X2': array([0.06389987], dtype=float32),\n",
       " \"spline(Z1, bs='bs', df=24)\": array([-0.02716911, -0.1502083 ,  0.08915941,  0.00341093, -0.10176762,\n",
       "        -0.22853501, -0.1698506 , -0.07311463,  0.06400301, -0.01527868,\n",
       "        -0.16755626, -0.165629  , -0.05728169,  0.11317274,  0.04690243,\n",
       "         0.01842467,  0.3821651 ,  0.24816796, -0.14492553, -0.10131226,\n",
       "         0.23916532,  0.10972033,  0.1978991 ,  0.21067359], dtype=float32),\n",
       " \"spline(Z2, bs='bs', df=24)\": array([ 0.242038  ,  0.36188853, -0.25710744, -0.23560256, -0.11818494,\n",
       "        -0.04522917, -0.02499777, -0.1784563 , -0.42915365, -0.00850329,\n",
       "        -0.25722575, -0.41706994, -0.12326404,  0.28168833,  0.08507476,\n",
       "         0.04096813,  0.26483554,  0.0877103 ,  0.10024875, -0.10896218,\n",
       "        -0.3801032 , -0.08763045,  0.09155629,  0.28837582], dtype=float32)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssdr.coeff(\"loc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ssdr.coeff(\"loc\")[\"spline(Z1, bs='bs', df=24)\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the result rows.\n",
    "results = []\n",
    "\n",
    "# Loop over each parameter group in degrees_of_freedom.\n",
    "for k in degrees_of_freedom.keys():\n",
    "    # Get the coefficient dictionary for parameter group k.\n",
    "    # This dictionary is expected to have keys corresponding to feature names.\n",
    "    \n",
    "    # Combine the features (if you want to process both kinds together)\n",
    "    coeff_dict = ssdr.coeff(k)\n",
    "    \n",
    "    for feature in coeff_dict.keys():\n",
    "        # Extract the point estimate for the feature.\n",
    "        # (Assuming ssdr.coeff(k)[feature] returns a list/array where the first element is the estimate.)                \n",
    "        # Append a dictionary with the desired columns.\n",
    "        results.append({\n",
    "            'scenario_index': scenario_index,  # scenario_index should be defined in your code\n",
    "            'param_y': k,\n",
    "            'param_eta': feature,\n",
    "            'value': coeff_dict[feature]\n",
    "        })\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame.\n",
    "df_results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "scenario_index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "param_y",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "param_eta",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "value",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "46b2341e-56b3-4bf1-8dcd-501a53cfcf8d",
       "rows": [
        [
         "0",
         "n_100_rep_0_dist_gaussian_homo_SNR_1",
         "loc",
         "X1",
         "[-0.01665793]"
        ],
        [
         "1",
         "n_100_rep_0_dist_gaussian_homo_SNR_1",
         "loc",
         "X2",
         "[0.20231669]"
        ],
        [
         "2",
         "n_100_rep_0_dist_gaussian_homo_SNR_1",
         "loc",
         "spline(Z1, bs=\"bs\")",
         "[-0.33227366 -0.4185705  -0.04214008  0.60077035]"
        ],
        [
         "3",
         "n_100_rep_0_dist_gaussian_homo_SNR_1",
         "loc",
         "spline(Z2, bs=\"bs\")",
         "[0.1305335  0.08974188 0.04103843 0.25026676]"
        ],
        [
         "4",
         "n_100_rep_0_dist_gaussian_homo_SNR_1",
         "scale",
         "Intercept",
         "[0.3417374]"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario_index</th>\n",
       "      <th>param_y</th>\n",
       "      <th>param_eta</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n_100_rep_0_dist_gaussian_homo_SNR_1</td>\n",
       "      <td>loc</td>\n",
       "      <td>X1</td>\n",
       "      <td>[-0.016657928]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n_100_rep_0_dist_gaussian_homo_SNR_1</td>\n",
       "      <td>loc</td>\n",
       "      <td>X2</td>\n",
       "      <td>[0.20231669]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n_100_rep_0_dist_gaussian_homo_SNR_1</td>\n",
       "      <td>loc</td>\n",
       "      <td>spline(Z1, bs=\"bs\")</td>\n",
       "      <td>[-0.33227366, -0.4185705, -0.04214008, 0.60077...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n_100_rep_0_dist_gaussian_homo_SNR_1</td>\n",
       "      <td>loc</td>\n",
       "      <td>spline(Z2, bs=\"bs\")</td>\n",
       "      <td>[0.1305335, 0.08974188, 0.041038435, 0.25026676]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n_100_rep_0_dist_gaussian_homo_SNR_1</td>\n",
       "      <td>scale</td>\n",
       "      <td>Intercept</td>\n",
       "      <td>[0.3417374]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         scenario_index param_y            param_eta  \\\n",
       "0  n_100_rep_0_dist_gaussian_homo_SNR_1     loc                   X1   \n",
       "1  n_100_rep_0_dist_gaussian_homo_SNR_1     loc                   X2   \n",
       "2  n_100_rep_0_dist_gaussian_homo_SNR_1     loc  spline(Z1, bs=\"bs\")   \n",
       "3  n_100_rep_0_dist_gaussian_homo_SNR_1     loc  spline(Z2, bs=\"bs\")   \n",
       "4  n_100_rep_0_dist_gaussian_homo_SNR_1   scale            Intercept   \n",
       "\n",
       "                                               value  \n",
       "0                                     [-0.016657928]  \n",
       "1                                       [0.20231669]  \n",
       "2  [-0.33227366, -0.4185705, -0.04214008, 0.60077...  \n",
       "3   [0.1305335, 0.08974188, 0.041038435, 0.25026676]  \n",
       "4                                        [0.3417374]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0167,  0.2023, -0.3323, -0.4186, -0.0421,  0.6008,  0.1305,  0.0897,\n",
       "          0.0410,  0.2503]], requires_grad=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_weights = net_loc.structured_head.weight\n",
    "structured_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_head_weights = net_loc.deep_head.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.6015,  0.5054,  0.4911, -0.1429, -0.8494,  0.5513,  0.6371,  0.5734,\n",
       "         -0.1773,  0.4729,  0.4953,  0.5017, -0.2171,  0.5962, -0.2339,  0.4576]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_head_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_head_weights = net_loc.structured_head.weight\n",
    "structured_head_bias = net_loc.structured_head.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sddr.utils.dataset.SddrDataset at 0x146ee5aa9a00>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssdr.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Append the method to the Sddr class (if not editing the class source directly)\n",
    "# For example, if your Sddr class is defined in a module, you can add the method as shown above.\n",
    "\n",
    "# ---------------------------\n",
    "# Example usage:\n",
    "# ---------------------------\n",
    "# Assume `sddr` is your trained Sddr object and `train_dataset` is your full training dataset.\n",
    "ssdr.net.eval()  # Ensure dropout is off\n",
    "full_latent_features = ssdr.get_full_latent_features(ssdr.dataset)\n",
    "\n",
    "# Optionally, you can also extract the deep head weights.\n",
    "# For example, for parameter \"loc\":\n",
    "if \"loc\" in ssdr.single_parameter_sddr_list:\n",
    "    deep_head_weights = ssdr.single_parameter_sddr_list[\"loc\"].deep_head.weight.detach().cpu()\n",
    "    print(\"Deep head weights for 'loc':\", deep_head_weights)\n",
    "\n",
    "# Now, full_latent_features is a dictionary (e.g., {'loc': tensor([...]), 'scale': tensor([...])})\n",
    "# You can, for example, build a new model that takes these latent features as input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ssdr.predict(df, unstructured_data=unstructured_data)[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([0.54340494, 0.27836939, 0.42451759, 0.84477613, 0.00471886,\n",
       "         0.12156912, 0.67074908, 0.82585276, 0.13670659, 0.57509333,\n",
       "         0.89132195, 0.20920212, 0.18532822, 0.10837689, 0.21969749,\n",
       "         0.97862378, 0.81168315, 0.17194101, 0.81622475, 0.27407375,\n",
       "         0.43170418, 0.94002982, 0.81764938, 0.33611195, 0.17541045,\n",
       "         0.37283205, 0.00568851, 0.25242635, 0.79566251, 0.01525497,\n",
       "         0.59884338, 0.60380454, 0.10514769, 0.38194344, 0.03647606,\n",
       "         0.89041156, 0.98092086, 0.05994199, 0.89054594, 0.5769015 ,\n",
       "         0.74247969, 0.63018394, 0.58184219, 0.02043913, 0.21002658,\n",
       "         0.54468488, 0.76911517, 0.25069523, 0.28589569, 0.85239509,\n",
       "         0.97500649, 0.88485329, 0.35950784, 0.59885895, 0.35479561,\n",
       "         0.34019022, 0.17808099, 0.23769421, 0.04486228, 0.50543143,\n",
       "         0.37625245, 0.5928054 , 0.62994188, 0.14260031, 0.9338413 ,\n",
       "         0.94637988, 0.60229666, 0.38776628, 0.363188  , 0.20434528,\n",
       "         0.27676506, 0.24653588, 0.173608  , 0.96660969, 0.9570126 ,\n",
       "         0.59797368, 0.73130075, 0.34038522, 0.0920556 , 0.46349802,\n",
       "         0.50869889, 0.08846017, 0.52803522, 0.99215804, 0.39503593,\n",
       "         0.33559644, 0.80545054, 0.75434899, 0.31306644, 0.63403668,\n",
       "         0.54040458, 0.29679375, 0.1107879 , 0.3126403 , 0.45697913,\n",
       "         0.65894007, 0.25425752, 0.64110126, 0.20012361, 0.65762481]),\n",
       "  tensor([ 8.0883e-02,  1.2922e-02, -1.1835e-01, -6.1060e-02, -2.1832e-02,\n",
       "          -4.3346e-02,  2.9631e-01, -1.0613e-01, -7.9769e-02,  5.6452e-02,\n",
       "           1.3872e-01, -1.7536e-01, -1.9599e-01, -1.4875e-02, -1.5280e-01,\n",
       "           1.9435e-01, -1.0882e-01, -1.7706e-01, -1.1079e-01,  3.1367e-03,\n",
       "          -1.0664e-01,  1.6121e-01, -1.1086e-01, -5.3669e-02, -1.8398e-01,\n",
       "          -1.5723e-01, -3.0899e-02, -6.1478e-02, -8.1547e-02, -8.0866e-02,\n",
       "           4.0214e-02,  4.7371e-02, -8.2018e-03, -1.5909e-01, -3.3405e-02,\n",
       "           1.3614e-01,  1.9854e-01,  3.2820e-02,  1.3652e-01,  5.4428e-02,\n",
       "           1.3628e-01,  1.6574e-01,  4.8967e-02, -8.3643e-02, -1.7377e-01,\n",
       "           8.0710e-02,  1.4943e-02, -6.6898e-02,  2.5366e-02, -3.0197e-02,\n",
       "           1.8769e-01,  1.1779e-01, -1.3668e-01,  4.0227e-02, -1.2303e-01,\n",
       "          -6.9138e-02, -1.8844e-01, -1.0579e-01, -1.9666e-04,  4.4992e-02,\n",
       "          -1.5882e-01,  3.9373e-02,  1.6442e-01, -9.5467e-02,  1.6373e-01,\n",
       "           1.5975e-01,  4.4455e-02, -1.5710e-01, -1.4500e-01, -1.8387e-01,\n",
       "           9.4657e-03, -7.9708e-02, -1.8053e-01,  1.7335e-01,  1.6252e-01,\n",
       "           3.9630e-02,  1.8349e-01, -6.9891e-02,  1.6698e-02, -4.3773e-02,\n",
       "           5.0564e-02,  2.2418e-02,  7.5040e-02,  2.1601e-01, -1.5266e-01,\n",
       "          -5.1769e-02, -1.0185e-01,  8.2123e-02,  1.2747e-02,  1.8638e-01,\n",
       "           8.0877e-02,  3.0599e-02, -1.9920e-02,  1.3561e-02, -5.7852e-02,\n",
       "           2.7891e-01, -5.5692e-02,  2.2075e-01, -1.8982e-01,  2.7598e-01])),\n",
       " (array([0.77828922, 0.7795984 , 0.61032815, 0.30900035, 0.69773491,\n",
       "         0.8596183 , 0.62532376, 0.98240783, 0.97650013, 0.16669413,\n",
       "         0.02317814, 0.16074455, 0.92349683, 0.95354985, 0.21097842,\n",
       "         0.36052525, 0.54937526, 0.27183085, 0.46060162, 0.69616156,\n",
       "         0.5003559 , 0.71607099, 0.52595594, 0.00139902, 0.39470029,\n",
       "         0.49216697, 0.40288033, 0.3542983 , 0.50061432, 0.44517663,\n",
       "         0.09043279, 0.27356292, 0.9434771 , 0.02654464, 0.03999869,\n",
       "         0.28314036, 0.58234417, 0.9908928 , 0.99264224, 0.99311737,\n",
       "         0.11004833, 0.66448145, 0.52398683, 0.17314991, 0.94296024,\n",
       "         0.24186009, 0.99893227, 0.58269382, 0.183279  , 0.38684542,\n",
       "         0.18967353, 0.41077067, 0.59468007, 0.71658609, 0.48689148,\n",
       "         0.30958982, 0.57744137, 0.44170782, 0.3596781 , 0.32133193,\n",
       "         0.20820724, 0.45125862, 0.49184291, 0.89907631, 0.72936046,\n",
       "         0.77008977, 0.37543925, 0.34373954, 0.65503521, 0.71103799,\n",
       "         0.11353758, 0.13302869, 0.45603906, 0.15973623, 0.9616419 ,\n",
       "         0.83761574, 0.52016069, 0.21827226, 0.13491872, 0.97907035,\n",
       "         0.7070435 , 0.85997556, 0.38717263, 0.25083402, 0.29943802,\n",
       "         0.85689553, 0.47298399, 0.66327705, 0.80572861, 0.2529805 ,\n",
       "         0.07957344, 0.73276061, 0.96139748, 0.95380473, 0.49049905,\n",
       "         0.63219206, 0.73299502, 0.9024095 , 0.16224692, 0.40588132]),\n",
       "  tensor([ 0.1759,  0.1745,  0.1838, -0.1041,  0.2512,  0.0668,  0.1530,  0.0411,\n",
       "          -0.0219, -0.0875,  0.3163, -0.1020, -0.1799, -0.1943, -0.0026, -0.2469,\n",
       "           0.1757,  0.0053, -0.2589,  0.2471, -0.1868,  0.2775,  0.0190,  0.3078,\n",
       "          -0.0778, -0.2460, -0.0539, -0.2554, -0.1848, -0.1833, -0.0986,  0.0024,\n",
       "          -0.2165,  0.3053,  0.2382, -0.0176,  0.2424,  0.1604,  0.1940,  0.2038,\n",
       "          -0.1541,  0.1556,  0.0036, -0.0720, -0.2167,  0.0237,  0.3541,  0.2420,\n",
       "          -0.0496, -0.1163, -0.0369, -0.0511,  0.2218,  0.2775, -0.2740, -0.1066,\n",
       "           0.2456, -0.1648, -0.2488, -0.1596, -0.0064, -0.2153, -0.2480, -0.0712,\n",
       "           0.2640,  0.1856, -0.1821, -0.2448,  0.1413,  0.2754, -0.1581, -0.1552,\n",
       "          -0.2389, -0.1045, -0.1504,  0.1131, -0.0269,  0.0064, -0.1530,  0.0048,\n",
       "           0.2706,  0.0658, -0.1145,  0.0238, -0.0669,  0.0736, -0.2928,  0.1532,\n",
       "           0.1506,  0.0232, -0.0404,  0.2574, -0.1521, -0.1932, -0.2560,  0.1437,\n",
       "           0.2569, -0.0862, -0.0984, -0.0506]))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssdr.predict(df, unstructured_data=unstructured_data)[1]['loc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ssdr.predict(df, unstructured_data=unstructured_data)[1]['loc'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.13102287 0.         0.15486272 ... 0.         0.         0.16163117]\n",
      " [0.         0.19298601 0.         ... 0.3902848  0.         0.27889434]\n",
      " [0.         0.         0.         ... 0.22374676 0.00426558 0.50957525]\n",
      " ...\n",
      " [0.         0.39148313 0.35076192 ... 0.43440923 0.         0.45768496]\n",
      " [0.         0.31406093 0.         ... 0.5324676  0.21987693 0.7418438 ]\n",
      " [0.         0.         0.         ... 0.33558524 0.         0.18744768]]\n"
     ]
    }
   ],
   "source": [
    "print(U_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dict = {}\n",
    "eval_dict[k] = eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_to_index = {\"rate\": 0, \"loc\": 0, \"scale\": 1}\n",
    "coverage_rates = {}\n",
    "for param, partial_effects in eval_dict.items():\n",
    "    if len(partial_effects)>0:\n",
    "        coverage_rates[param] = {}\n",
    "        # For Gaussian (or gamma) cases, we assume true_nonlinear_effects is a dict with keys matching the parameter names.\n",
    "        # For Poisson, true_nonlinear_effects is a list.\n",
    "        true_effects = nonlinear_effects[:,:,param_to_index[param]]\n",
    "        for idx, effect in enumerate(partial_effects):\n",
    "            if len(effect) == 6:\n",
    "                feature, _, ci950, ci951, _, _ = effect\n",
    "                \n",
    "                # Get the corresponding true effect for this spline; shape: (n_samples, )\n",
    "                true_effect = true_effects[idx, :]\n",
    "                # plot_true_and_ci(true_effect, effect, param, idx, f\"{save_path}/plot_{scenario_index}\")\n",
    "                # Sort both the feature and true effect to ensure proper alignment.\n",
    "                sort_idx = np.argsort(feature)\n",
    "                sorted_feature = np.array(feature)[sort_idx]\n",
    "                sorted_ci950 = ci950[sort_idx]\n",
    "                sorted_ci951 = ci951[sort_idx]\n",
    "                sorted_true_effect = true_effect[sort_idx]\n",
    "                \n",
    "                # Now compute coverage.\n",
    "                covered = np.logical_and(sorted_true_effect >= sorted_ci950, sorted_true_effect <= sorted_ci951)\n",
    "                coverage_rate = np.mean(covered)\n",
    "                coverage_rates[param][f'spline_{idx}'] = coverage_rate\n",
    "            else:\n",
    "                coverage_rates[param][f'spline_{idx}'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dict = {}\n",
    "for k in degrees_of_freedom.keys():\n",
    "    eval_results = ssdr.eval(k, plot=False)\n",
    "    eval_dict[k] = eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(eval_dict['loc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(eval_dict['loc'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssdr.eval('scale', plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scenario_index = f\"n_{100}_rep_{1}\"\n",
    "nonlinear_effects = read_with_var_name('nonlinear_effects', 'npy', read_path, scenario_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_nonlinear_effects = nonlinear_effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute coverage rates for each parameter.\n",
    "coverage_rates = {}\n",
    "for param, partial_effects in eval_dict.items():\n",
    "    coverage_rates[param] = {}\n",
    "    # For Gaussian (or gamma) cases, we assume true_nonlinear_effects is a dict with keys matching the parameter names.\n",
    "    # For Poisson, true_nonlinear_effects is a list.\n",
    "    if isinstance(true_nonlinear_effects, dict):\n",
    "        true_effects = true_nonlinear_effects[param]\n",
    "    else:\n",
    "        true_effects = true_nonlinear_effects\n",
    "\n",
    "    for idx, effect in enumerate(partial_effects):\n",
    "        if len(effect) == 6:\n",
    "            _, _, ci950, ci951, _, _ = effect\n",
    "            true_effect = true_effects[idx]\n",
    "            covered = np.logical_and(true_effect >= ci950, true_effect <= ci951)\n",
    "            coverage_rate = np.mean(covered)\n",
    "            coverage_rates[param][f'spline_{idx}'] = coverage_rate\n",
    "        else:\n",
    "            coverage_rates[param][f'spline_{idx}'] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm that the penalty matrix is structured correctly: \n",
    "# all zeros for the linear components and non-zero values for the spline components.\n",
    "import torch\n",
    "\n",
    "# Assume P_rate is the penalty matrix and term_slices is the OrderedDict from design_info:\n",
    "P_rate = result.prepare_data.P['rate']  # e.g. a torch tensor of shape [11, 11]\n",
    "term_slices = result.prepare_data.structured_matrix_design_info['rate'].term_name_slices\n",
    "\n",
    "# Define the term names for linear and spline parts\n",
    "linear_terms = ['Intercept', 'X1', 'X2']\n",
    "spline_terms = ['spline(Z1, bs=\"bs\")', 'spline(Z2, bs=\"bs\")']\n",
    "\n",
    "# Check linear part: should be all zeros.\n",
    "for term in linear_terms:\n",
    "    sl = term_slices[term]\n",
    "    block = P_rate[sl, sl]\n",
    "    print(f\"Penalty block for {term}:\")\n",
    "    print(block)\n",
    "    is_zero = torch.allclose(block, torch.zeros_like(block))\n",
    "    print(f\"All zeros: {is_zero}\\n\")\n",
    "\n",
    "# Check spline part: should be non-zero.\n",
    "for term in spline_terms:\n",
    "    sl = term_slices[term]\n",
    "    block = P_rate[sl, sl]\n",
    "    print(f\"Penalty block for {term}:\")\n",
    "    print(block)\n",
    "    # Check if there's at least one non-zero element:\n",
    "    non_zero = not torch.allclose(block, torch.zeros_like(block))\n",
    "    print(f\"Non-zero: {non_zero}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from patsy import build_design_matrices\n",
    "spline_info = result.prepare_data.dm_info_dict['rate']['spline_info']\n",
    "non_spline_info = result.prepare_data.dm_info_dict['rate']['non_spline_info']\n",
    "structured_matrix = build_design_matrices([result.prepare_data.structured_matrix_design_info['rate']],\n",
    "                                          data, NA_action='raise', return_type='dataframe')[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for spline_slice, spline_input_features in zip(spline_info['list_of_spline_slices'], \n",
    "                                                   spline_info['list_of_spline_input_features']):\n",
    "    X = structured_matrix.iloc[:,spline_slice]\n",
    "    constraints = []\n",
    "    for non_spline_slice, non_spline_input_features in zip(\n",
    "            non_spline_info['list_of_non_spline_slices'], \n",
    "            non_spline_info['list_of_non_spline_input_features']):\n",
    "        print(\"non_spline_input_features\", set(non_spline_input_features))\n",
    "        print(\"spline_input_features\", set(spline_input_features))\n",
    "        if set(non_spline_input_features).issubset(set(spline_input_features)):\n",
    "            constraints.append(structured_matrix.iloc[:,non_spline_slice].values)\n",
    "    \n",
    "    if len(constraints)>0:\n",
    "        constraints = np.concatenate(constraints,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.prepare_data.network_info_dict['rate']['orthogonalization_pattern']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.net.single_parameter_sddr_list['rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in result.train_loader:\n",
    "    # for each batch\n",
    "    target = batch['target'].float()\n",
    "    datadict = batch['datadict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = datadict['rate'][\"structured\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadict['rate'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'dnn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadict['rate'][key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = result.prepare_data.deep_models_dict[key]\n",
    "# Uhat_net = net(datadict['rate'][key])\n",
    "\n",
    "# orthogonalize the output of the neural network with respect to the parts of the structured part,\n",
    "# that contain the same input as the neural network\n",
    "if len(result.prepare_data.network_info_dict['rate']['orthogonalization_pattern'][key]) >0:\n",
    "    X_sliced_with_orthogonalization_pattern = torch.cat([X[:,sl] for sl in result.prepare_data.network_info_dict['rate']['orthogonalization_pattern'][key]],1)\n",
    "    Q, R = torch.qr(X_sliced_with_orthogonalization_pattern)\n",
    "    # Utilde_net = result.prepare_data.network_info_dict['rate']._orthog_layer(Q, Uhat_net)\n",
    "# else:\n",
    "    # Utilde_net = Uhat_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sliced_with_orthogonalization_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.prepare_data.network_info_dict['rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.prepare_data.network_info_dict['rate']['orthogonalization_pattern']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.coeff('rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.get_distribution().mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result.get_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_effects_loc = result.eval('rate',plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_effects_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(partial_effects_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature, partial_effect, ci950, ci951, ci250, ci251 = partial_effects_loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ci950"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = ['deep_ensemble', 'dropout_sampling', 'last_layer']\n",
    "# n_list = [100, 500, 1000]\n",
    "n_list = [10]\n",
    "distribution_list = [\"poisson\", \"gamma\", \"gaussian\"]\n",
    "SNR_list=[1,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = list(product(distribution_list, SNR_list, method))\n",
    "combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_with_var_name(var_name, var_type, save_path, scenario_index):\n",
    "    if var_type == 'npy':\n",
    "        return np.load(f\"{save_path}/{var_name}_{scenario_index}.npy\")\n",
    "    if var_type == 'keras':\n",
    "        return tf.keras.models.load_model(f\"{save_path}/{var_name}_{scenario_index}.keras\")\n",
    "\n",
    "scenario_index = f\"n_{10}_rep_{4}\"\n",
    "save_path = \"../data_generation/output_debug_local\"\n",
    "U_k = read_with_var_name('U_k', 'npy', save_path, scenario_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssdr.dataset.prepared_data['loc'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etas = np.zeros((10, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etas[:, 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etas[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
