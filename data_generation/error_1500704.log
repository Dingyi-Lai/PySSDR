
The following have been reloaded with a version change:
  1) devel/cuda/12.2 => devel/cuda/12.4

Error.  nthreads cannot be larger than environment variable "NUMEXPR_MAX_THREADS" (64)2025-02-10 14:20:43.472924: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-10 14:20:43.588393: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1739193643.640305 2646111 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1739193643.653286 2646111 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-02-10 14:20:43.743207: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
INFO:root:Starting parallel dataset generation...
2025-02-10 14:20:48.609104: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2025-02-10 14:20:48.609102: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2025-02-10 14:20:48.609173: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:137] retrieving CUDA diagnostic information for host: haicn1711.localdomain
2025-02-10 14:20:48.609175: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:137] retrieving CUDA diagnostic information for host: haicn1711.localdomain
2025-02-10 14:20:48.609189: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:144] hostname: haicn1711.localdomain
2025-02-10 14:20:48.609191: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:144] hostname: haicn1711.localdomain
2025-02-10 14:20:48.609292: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:168] libcuda reported version is: 550.54.15
2025-02-10 14:20:48.609293: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:168] libcuda reported version is: 550.54.15
2025-02-10 14:20:48.609324: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:172] kernel reported version is: 550.54.15
2025-02-10 14:20:48.609325: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:172] kernel reported version is: 550.54.15
2025-02-10 14:20:48.609333: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:259] kernel version seems to match DSO: 550.54.15
2025-02-10 14:20:48.609337: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:259] kernel version seems to match DSO: 550.54.15
INFO:root:Generating dataset: Number of obs 10 | Replication 0
INFO:root:Generating dataset: Number of obs 10 | Replication 1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/usr/lib64/python3.9/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/usr/lib64/python3.9/multiprocessing/pool.py", line 51, in starmapstar
    return list(itertools.starmap(args[0], args[1]))
  File "/hkfs/home/haicore/scc/pa6512/PySSDR/data_generation/data_generation_parallel.py", line 213, in generate_task
    save_with_var_name(X, 'X', 'npy', save_path, scenario_index)
  File "/hkfs/home/haicore/scc/pa6512/PySSDR/data_generation/data_generation_parallel.py", line 184, in save_with_var_name
    np.save(f"{save_path}/{var_name}_{scenario_index}.npy", var)
  File "/home/scc/pa6512/.local/lib/python3.9/site-packages/numpy/lib/_npyio_impl.py", line 570, in save
    file_ctx = open(file, "wb")
FileNotFoundError: [Errno 2] No such file or directory: '/scratch/slurm_tmpdir/job_1500704/output/X_n_10_rep_0.npy'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/hkfs/home/haicore/scc/pa6512/PySSDR/data_generation/data_generation_parallel.py", line 309, in <module>
    scenarios_generate(n_list, distribution_list, SNR_list, grid_size, alpha_l, beta_nl, n_rep, n_cores=n_core,
  File "/hkfs/home/haicore/scc/pa6512/PySSDR/data_generation/data_generation_parallel.py", line 259, in scenarios_generate
    pool.starmap(generate_task, [(i, distribution_list, SNR_list, grid_size,
  File "/usr/lib64/python3.9/multiprocessing/pool.py", line 372, in starmap
    return self._map_async(func, iterable, starmapstar, chunksize).get()
  File "/usr/lib64/python3.9/multiprocessing/pool.py", line 771, in get
    raise self._value
  File "/usr/lib64/python3.9/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/usr/lib64/python3.9/multiprocessing/pool.py", line 51, in starmapstar
    return list(itertools.starmap(args[0], args[1]))
  File "/hkfs/home/haicore/scc/pa6512/PySSDR/data_generation/data_generation_parallel.py", line 213, in generate_task
    save_with_var_name(X, 'X', 'npy', save_path, scenario_index)
  File "/hkfs/home/haicore/scc/pa6512/PySSDR/data_generation/data_generation_parallel.py", line 184, in save_with_var_name
    np.save(f"{save_path}/{var_name}_{scenario_index}.npy", var)
  File "/home/scc/pa6512/.local/lib/python3.9/site-packages/numpy/lib/_npyio_impl.py", line 570, in save
    file_ctx = open(file, "wb")
FileNotFoundError: [Errno 2] No such file or directory: '/scratch/slurm_tmpdir/job_1500704/output/X_n_10_rep_0.npy'
cp: cannot stat '/scratch/slurm_tmpdir/job_1500704/output': No such file or directory
