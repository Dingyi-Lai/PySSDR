{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# todo\n",
    "\n",
    "sddr single:\n",
    "input to NN cannot be dicts\n",
    "\n",
    "\n",
    "SDDR: may be we make our own get_parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Sddr_Single(nn.Module):\n",
    "    \n",
    "    def __init__(self, deep_models_dict, deep_shapes, struct_shapes, P):\n",
    "        \"\"\"\n",
    "        deep_models_dict: dictionary where key are names of deep models and values are objects that define the deep models\n",
    "        struct_shapes: number of structural features\n",
    "        P: numpy matrix for the smoothing regularization (with added zero matrix in the beginning for the linear part)\n",
    "        \n",
    "        \"\"\"\n",
    "        super(Sddr_Single, self).__init__()\n",
    "        self.P = P\n",
    "        self.deep_models_dict = deep_models_dict\n",
    "        \n",
    "        #register external neural networks\n",
    "        for key, value in deep_models_dict.items():\n",
    "            self.add_module(key,value)\n",
    "        \n",
    "        \n",
    "        self.structured_head = nn.Linear(struct_shapes,1, bias = False)\n",
    "        \n",
    "        if len(deep_models_dict) != 0:\n",
    "            output_size_of_deep_models  = sum([deep_shapes[key] for key in deep_shapes.keys()])\n",
    "            self.deep_head = nn.Linear(output_size_of_deep_models,1, bias = False)\n",
    "            self._deep_models_exist = True\n",
    "        else:\n",
    "            self._deep_models_exist = False\n",
    "        \n",
    "              \n",
    "        \n",
    "    def _orthog_layer(self, Q, Uhat):\n",
    "        \"\"\"\n",
    "        Utilde = Uhat - QQTUhat\n",
    "        \"\"\"\n",
    "        Projection_Matrix = Q @ Q.T\n",
    "        Utilde = Uhat - Projection_Matrix @ Uhat\n",
    "        \n",
    "        return Utilde\n",
    "    \n",
    "    \n",
    "    def forward(self, datadict):\n",
    "        \"\"\"Comment 6.8.2020 We checked that we can actually have a dictionary as an input here. that should work fine\"\"\"\n",
    "        \n",
    "        X = datadict[\"structured\"]\n",
    "        \n",
    "        if self._deep_models_exist:\n",
    "            Q, R = torch.qr(X)\n",
    "\n",
    "            Uhat_list = []\n",
    "            for key in self.deep_models_dict.keys(): #assume that the input for the NN has the name of the NN as key\n",
    "                net = self.deep_models_dict[key]\n",
    "                Uhat_list.append(net(datadict[key]))\n",
    "            \n",
    "            Uhat = torch.cat(Uhat_list, dim = 1) #concatenate the outputs of the deep NNs\n",
    "\n",
    "            Utilde = self._orthog_layer(Q, Uhat)\n",
    "            \n",
    "            deep_pred = self.deep_head(Utilde)\n",
    "        else:\n",
    "            deep_pred = 0\n",
    "        \n",
    "        structured_pred = self.structured_head(X)\n",
    "        \n",
    "        pred = structured_pred + deep_pred\n",
    "        \n",
    "        return pred\n",
    "    \n",
    "    def get_regularization(self):\n",
    "        P = torch.from_numpy(self.P).float() # should have shape struct_shapes x struct_shapes, numpy array\n",
    "        weights = self.structured_head.weight #should have shape 1 x struct_shapes\n",
    "        \n",
    "        \n",
    "        regularization = weights @ P @ weights.T\n",
    "        \n",
    "        return regularization\n",
    "        \n",
    "        \n",
    "        \n",
    "class Sddr(nn.Module):\n",
    "    \n",
    "    def __init__(self, family, regularization_params, parsed_formula_contents):\n",
    "        \"\"\"\n",
    "        family: string e.g. \"gaussian\", \"binomial\"...\n",
    "        regularization_params: smoothing parameters\n",
    "        parsed_formula_contents: dictionary with keys being parameters of the distribution, e.g. \"eta\" and \"scale\"\n",
    "        and values being dicts with keys deep_models_dict, struct_shapes and P (as used in Sddr_Single)\n",
    "        \"\"\"\n",
    "        super(Sddr, self).__init__()\n",
    "        self.family = family\n",
    "        self.regularization_params = regularization_params\n",
    "        self.parameter_names = parsed_formula_contents.keys\n",
    "        self.single_parameter_sddr_list = dict()\n",
    "        for key, value in parsed_formula_contents.items():\n",
    "            deep_models_dict = value[\"deep_models_dict\"]\n",
    "            deep_shapes = value[\"deep_shapes\"]\n",
    "            struct_shapes = value[\"struct_shapes\"]\n",
    "            P = value[\"P\"]\n",
    "            self.single_parameter_sddr_list[key] = Sddr_Single(deep_models_dict, deep_shapes, struct_shapes, P)\n",
    "            \n",
    "            #register the Sddr_Single network\n",
    "            self.add_module(key,self.single_parameter_sddr_list[key])\n",
    "                \n",
    "\n",
    "        #define distributional layer\n",
    "        if family == \"normal\":\n",
    "            self.distribution_layer_type = torch.distributions.normal.Normal\n",
    "        elif family == \"poisson\":\n",
    "            self.distribution_layer_type = torch.distributions.poisson.Poisson\n",
    "    \n",
    "    def _distribution_trafos(self,pred):\n",
    "        #applies the specific transformations to the prediction so they they correspond to the restrictions\n",
    "        #of the parameters\n",
    "        #this is family specific\n",
    "        pred_trafo = dict()\n",
    "        add_const = 1e-8\n",
    "        \n",
    "        family = self.family\n",
    "        if family == \"normal\":\n",
    "            pred_trafo[\"loc\"] = pred[\"loc\"]\n",
    "            pred_trafo[\"scale\"] = add_const + pred[\"scale\"].exp()\n",
    "        elif family == \"poisson\":\n",
    "            pred_trafo[\"rate\"] = add_const + pred[\"rate\"].exp()\n",
    "        \n",
    "        return pred_trafo\n",
    "    \n",
    "    def forward(self,meta_datadict):\n",
    "        \n",
    "        self.regul = 0\n",
    "        pred = dict()\n",
    "        for parameter_name, data_dict  in meta_datadict.items():\n",
    "            sddr_net = self.single_parameter_sddr_list[parameter_name]\n",
    "            pred[parameter_name] = sddr_net(data_dict)\n",
    "            self.regul += sddr_net.get_regularization()*self.regularization_params[parameter_name]\n",
    "            \n",
    "        predicted_parameters = self._distribution_trafos(pred)\n",
    "        \n",
    "        #define distributional layer (takes eta and scale)\n",
    "        self.distribution_layer = self.distribution_layer_type(**predicted_parameters)\n",
    "        \n",
    "        return self.distribution_layer\n",
    "    \n",
    "    def get_loss(self, Y):\n",
    "    \n",
    "#         regul = 0            # move to forward, or we need meta_datadict as input to get_loss\n",
    "#         for parameter_name, data_dict  in meta_datadict.items():\n",
    "#             sddr_net = self.single_parameter_sddr_list[parameter_name]\n",
    "#             regul += sddr_net.get_regularization()*self.regularization_params[parameter_name]\n",
    "        log_loss = -self.distribution_layer.log_prob(Y)\n",
    "        loss = log_loss + self.regul\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        x_csv = pd.read_csv (r'./example_data/simple_gam/X.csv',sep=';',header=None)\n",
    "        y_csv = pd.read_csv (r'./example_data/simple_gam/Y.csv',header=None)\n",
    "        B_csv = pd.read_csv (r'./example_data/simple_gam/B.csv',sep=';',header=None)\n",
    "        \n",
    "        self.struct_data = torch.from_numpy(B_csv.values).float()\n",
    "        self.deep_data = torch.from_numpy(x_csv.values).float()\n",
    "        self.y = torch.from_numpy(y_csv.values).float()\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        struct = self.struct_data[index]\n",
    "        deep = self.deep_data[index]\n",
    "        gt = self.y[index]\n",
    "        \n",
    "        datadict = {\"structured\": struct, \"dm1\": deep}\n",
    "        meta_datadict = dict()\n",
    "        meta_datadict[\"rate\"] = datadict\n",
    "        \n",
    "        return {'meta_datadict': meta_datadict, 'target': gt}        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.deep_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \n",
    "    family = \"poisson\"\n",
    "    \n",
    "    regularization_params = dict()\n",
    "    regularization_params[\"rate\"] = 1.   # already mutiplied in full_P\n",
    "    \n",
    "    deep_models_dict = {}\n",
    "    deep_shapes = {}\n",
    "    struct_shapes = 19\n",
    "    P = pd.read_csv (r'./example_data/simple_gam/full_P.csv',sep=';',header=None).values\n",
    "    \n",
    "    parsed_formula_contents = dict()\n",
    "    parsed_formula_contents[\"rate\"] = {\"deep_models_dict\": deep_models_dict, \"deep_shapes\": deep_shapes, \"struct_shapes\": struct_shapes, \"P\": P}\n",
    "    \n",
    "\n",
    "    dataset = MyDataset()\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=1000,\n",
    "    )\n",
    "    \n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    bignet = Sddr(family, regularization_params, parsed_formula_contents)\n",
    "    bignet = bignet.to(device)\n",
    "    optimizer = optim.RMSprop(bignet.parameters())\n",
    "\n",
    "    bignet.train()\n",
    "    print('Begin training ...')\n",
    "    for epoch in range(1, 2500):\n",
    "\n",
    "        for batch in loader:\n",
    "            target = batch['target'].to(device)\n",
    "            meta_datadict = batch['meta_datadict']          # .to(device) should be improved \n",
    "            meta_datadict['rate']['structured'] = meta_datadict['rate']['structured'].to(device)\n",
    "            meta_datadict['rate']['dm1'] = meta_datadict['rate']['dm1'].to(device)\n",
    "           \n",
    "            optimizer.zero_grad()\n",
    "            output = bignet(meta_datadict)\n",
    "            loss = torch.mean(bignet.get_loss(target))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if epoch % 100 == 0:\n",
    "            print('Train Epoch: {} \\t Loss: {:.6f}'.format(epoch,loss.item()))\n",
    "            \n",
    "    return list(bignet.parameters())[0].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training ...\n",
      "Train Epoch: 100 \t Loss: 558.418945\n",
      "Train Epoch: 200 \t Loss: 208.487625\n",
      "Train Epoch: 300 \t Loss: 1315.262085\n",
      "Train Epoch: 400 \t Loss: 2719.186279\n",
      "Train Epoch: 500 \t Loss: 1790.159790\n",
      "Train Epoch: 600 \t Loss: 1388.464233\n",
      "Train Epoch: 700 \t Loss: 1631.622681\n",
      "Train Epoch: 800 \t Loss: 1810.376587\n",
      "Train Epoch: 900 \t Loss: 1700.483521\n",
      "Train Epoch: 1000 \t Loss: 1644.985107\n",
      "Train Epoch: 1100 \t Loss: 1686.228149\n",
      "Train Epoch: 1200 \t Loss: 1705.023193\n",
      "Train Epoch: 1300 \t Loss: 1688.711182\n",
      "Train Epoch: 1400 \t Loss: 1682.726440\n",
      "Train Epoch: 1500 \t Loss: 1688.937622\n",
      "Train Epoch: 1600 \t Loss: 1690.718140\n",
      "Train Epoch: 1700 \t Loss: 1688.343750\n",
      "Train Epoch: 1800 \t Loss: 1687.751465\n",
      "Train Epoch: 1900 \t Loss: 1688.638794\n",
      "Train Epoch: 2000 \t Loss: 1688.807495\n",
      "Train Epoch: 2100 \t Loss: 1688.460327\n",
      "Train Epoch: 2200 \t Loss: 1688.376465\n",
      "Train Epoch: 2300 \t Loss: 1688.513184\n",
      "Train Epoch: 2400 \t Loss: 1688.554321\n"
     ]
    }
   ],
   "source": [
    "param = train()    # using adam optimizer can have smooth decreasing loss, using rmsprop the losses converge to a high value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.291429    0.17797086  1.2207029   0.18973732  0.7935956  -0.3610633\n",
      "  -0.74799216 -0.3180998  -4.526309    0.1839966   0.00499996 -0.00500001\n",
      "   0.00500004 -0.00499997  0.00499989 -0.00499997  0.00499996  0.00500007\n",
      "  -1.1196674 ]]\n"
     ]
    }
   ],
   "source": [
    "print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 1)\n"
     ]
    }
   ],
   "source": [
    "true_coeff = pd.read_csv (r'./example_data/simple_gam/true_coefficients.csv',sep=';',header=None).values\n",
    "B = pd.read_csv (r'./example_data/simple_gam/B.csv',sep=';',header=None).values\n",
    "X = pd.read_csv (r'./example_data/simple_gam/X.csv',sep=';',header=None).values\n",
    "print(true_coeff.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1)\n"
     ]
    }
   ],
   "source": [
    "hatY = np.matmul(B[:,1:10],true_coeff[1:10])\n",
    "print(hatY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_coeff = param\n",
    "pred_coeff = np.transpose(pred_coeff)\n",
    "\n",
    "hatY_pred = np.matmul(B[:,1:10],pred_coeff[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstCov = X[:,0] \n",
    "sortedHatY = [x for _,x in sorted(zip(firstCov,hatY))]\n",
    "sortedHatY_pred = [x for _,x in sorted(zip(firstCov,hatY_pred))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'PySDDR_coefficient')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(np.sort(firstCov), sortedHatY)\n",
    "plt.title('true_coefficient')\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(np.sort(firstCov), sortedHatY_pred)\n",
    "plt.title('PySDDR_coefficient')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test Sddr_Single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deep_shapes = {\"dm1\" : 5, \"dm2\" : 8}\n",
    "\n",
    "net2= nn.Sequential(nn.Linear(10,3),nn.ReLU(), nn.Linear(3,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_models_dict = {\"dm1\" : nn.Linear(10,5, bias = False), \"dm2\" : net2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct_shapes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.eye(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.ones(20,10)\n",
    "datadict = {\"structured\": data, \"dm1\": data, \"dm2\": data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Sddr_Single(deep_models_dict, deep_shapes, struct_shapes, P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0535],\n",
       "        [-0.0535],\n",
       "        [-0.0535],\n",
       "        [-0.0535],\n",
       "        [-0.0535],\n",
       "        [-0.0535],\n",
       "        [-0.0535],\n",
       "        [-0.0535],\n",
       "        [-0.0535],\n",
       "        [-0.0535],\n",
       "        [-0.0535],\n",
       "        [-0.0535],\n",
       "        [-0.0535],\n",
       "        [-0.0535],\n",
       "        [-0.0535],\n",
       "        [-0.0535],\n",
       "        [-0.0535],\n",
       "        [-0.0535],\n",
       "        [-0.0535],\n",
       "        [-0.0535]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 834,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(datadict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4237]], grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 835,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.get_regularization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0450,  0.3132, -0.2533, -0.0663,  0.1513,  0.1618, -0.1711,  0.1751,\n",
      "          0.2034, -0.1013],\n",
      "        [ 0.1457, -0.1887,  0.1578, -0.0177, -0.0884, -0.2482,  0.1933,  0.1885,\n",
      "          0.1223,  0.1456],\n",
      "        [-0.2872,  0.2873,  0.0221,  0.1267, -0.1926, -0.1228, -0.1013, -0.3115,\n",
      "         -0.1070,  0.3092],\n",
      "        [ 0.2323, -0.0799,  0.2225,  0.0531,  0.0059,  0.1509, -0.1401,  0.2687,\n",
      "          0.1905, -0.2308],\n",
      "        [-0.0035, -0.1833, -0.1211, -0.0225, -0.2246,  0.0049, -0.0644, -0.2636,\n",
      "         -0.1963, -0.2150]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1504,  0.0733, -0.0326,  0.1949, -0.0519, -0.0607, -0.0694,  0.0783,\n",
      "         -0.2417, -0.0261],\n",
      "        [-0.2603, -0.0073,  0.2344, -0.2413, -0.1986, -0.1428, -0.2594,  0.0118,\n",
      "         -0.1722,  0.1692],\n",
      "        [ 0.0141, -0.2903,  0.2476, -0.2810, -0.0929, -0.2952,  0.1316, -0.0939,\n",
      "          0.1434, -0.0977]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.2397, 0.1327, 0.1444], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0546, -0.4211, -0.0831],\n",
      "        [-0.4595, -0.5765,  0.0705],\n",
      "        [-0.3481,  0.2289,  0.0538],\n",
      "        [ 0.4195,  0.3138, -0.3943],\n",
      "        [ 0.0446, -0.0511, -0.4801],\n",
      "        [-0.2535, -0.4461, -0.2677],\n",
      "        [-0.4290,  0.4814, -0.0919],\n",
      "        [-0.1165,  0.1927,  0.2213]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.5256,  0.3756,  0.1480,  0.2058,  0.5054, -0.1609,  0.4523,  0.0451],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1689,  0.1397, -0.2754, -0.0093,  0.2364,  0.2882, -0.1848, -0.1166,\n",
      "         -0.2184,  0.2557]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.2170, -0.1446,  0.0003,  0.0607,  0.0386,  0.0032, -0.0363,  0.1704,\n",
      "          0.0879, -0.2120,  0.0019,  0.0112,  0.0591]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in net.parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.6698, -0.1423],\n",
      "        [ 0.5038,  0.0981],\n",
      "        [-0.1744, -0.1339],\n",
      "        [-0.4113,  0.3310],\n",
      "        [-0.4738, -0.2220]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1450,  0.1367,  0.1768,  0.1635, -0.0770,  0.1613, -0.0192,  0.0786,\n",
      "         -0.2005, -0.2166, -0.2112,  0.0377,  0.0462,  0.1035,  0.1268, -0.0238,\n",
      "          0.0126, -0.0916,  0.1823]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1046,  0.2764, -0.3203, -0.0709,  0.2124]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in bignet.parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Sddr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [],
   "source": [
    "family= \"normal\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_formula_contents = dict()\n",
    "parsed_formula_contents[\"loc\"] = {\"deep_models_dict\": deep_models_dict, \"deep_shapes\": deep_shapes, \"struct_shapes\": struct_shapes, \"P\": P}\n",
    "parsed_formula_contents[\"scale\"] = {\"deep_models_dict\": dict(), \"deep_shapes\": dict(), \"struct_shapes\": struct_shapes, \"P\": P}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularization_params = dict()\n",
    "\n",
    "regularization_params[\"loc\"] = 1.\n",
    "regularization_params[\"scale\"] = 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_datadict = dict()\n",
    "\n",
    "meta_datadict[\"loc\"] = datadict\n",
    "meta_datadict[\"scale\"] = {\"structured\": data}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [],
   "source": [
    "bignet = Sddr(family, regularization_params, parsed_formula_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loc\n",
      "scale\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Normal(loc: torch.Size([20, 1]), scale: torch.Size([20, 1]))"
      ]
     },
     "execution_count": 843,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bignet(meta_datadict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sddr_Single(\n",
      "  (dm1): Linear(in_features=10, out_features=5, bias=False)\n",
      "  (dm2): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=3, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=3, out_features=8, bias=True)\n",
      "  )\n",
      "  (structured_head): Linear(in_features=10, out_features=1, bias=False)\n",
      "  (deep_head): Linear(in_features=13, out_features=1, bias=False)\n",
      ")\n",
      "Sddr_Single(\n",
      "  (structured_head): Linear(in_features=10, out_features=1, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for i in bignet.children():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0450,  0.3132, -0.2533, -0.0663,  0.1513,  0.1618, -0.1711,  0.1751,\n",
      "          0.2034, -0.1013],\n",
      "        [ 0.1457, -0.1887,  0.1578, -0.0177, -0.0884, -0.2482,  0.1933,  0.1885,\n",
      "          0.1223,  0.1456],\n",
      "        [-0.2872,  0.2873,  0.0221,  0.1267, -0.1926, -0.1228, -0.1013, -0.3115,\n",
      "         -0.1070,  0.3092],\n",
      "        [ 0.2323, -0.0799,  0.2225,  0.0531,  0.0059,  0.1509, -0.1401,  0.2687,\n",
      "          0.1905, -0.2308],\n",
      "        [-0.0035, -0.1833, -0.1211, -0.0225, -0.2246,  0.0049, -0.0644, -0.2636,\n",
      "         -0.1963, -0.2150]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1504,  0.0733, -0.0326,  0.1949, -0.0519, -0.0607, -0.0694,  0.0783,\n",
      "         -0.2417, -0.0261],\n",
      "        [-0.2603, -0.0073,  0.2344, -0.2413, -0.1986, -0.1428, -0.2594,  0.0118,\n",
      "         -0.1722,  0.1692],\n",
      "        [ 0.0141, -0.2903,  0.2476, -0.2810, -0.0929, -0.2952,  0.1316, -0.0939,\n",
      "          0.1434, -0.0977]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.2397, 0.1327, 0.1444], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0546, -0.4211, -0.0831],\n",
      "        [-0.4595, -0.5765,  0.0705],\n",
      "        [-0.3481,  0.2289,  0.0538],\n",
      "        [ 0.4195,  0.3138, -0.3943],\n",
      "        [ 0.0446, -0.0511, -0.4801],\n",
      "        [-0.2535, -0.4461, -0.2677],\n",
      "        [-0.4290,  0.4814, -0.0919],\n",
      "        [-0.1165,  0.1927,  0.2213]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.5256,  0.3756,  0.1480,  0.2058,  0.5054, -0.1609,  0.4523,  0.0451],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1032, -0.2826,  0.2035,  0.0458,  0.1571, -0.0421, -0.2679,  0.3128,\n",
      "         -0.2690,  0.0560]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1785, -0.1413,  0.2162, -0.1403, -0.0686, -0.1385, -0.2135,  0.0126,\n",
      "         -0.0471, -0.1484,  0.2358, -0.1200,  0.1646]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1944, -0.1053, -0.2871, -0.0242, -0.0027,  0.2059,  0.0305,  0.2846,\n",
      "          0.0894, -0.0680]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in bignet.parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = torch.ones([20,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1])"
      ]
     },
     "execution_count": 847,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = bignet.get_loss(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.mean().backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing for dictionary as input to neural network module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class testnn(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(testnn, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.weights = nn.Parameter(torch.ones(784, 10) )\n",
    "        self.bias = nn.Parameter(torch.zeros(10))\n",
    "\n",
    "    def forward(self, xa):\n",
    "        #xa = datadict[\"a\"]\n",
    "        #xb = datadict[\"b\"]\n",
    "        out = xa @ self.weights + xa @ self.weights + self.bias\n",
    "        return out\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "testnn_obj = testnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.ones([784,10]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = testnn_obj(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_list = []\n",
    "for i in testnn_obj.parameters():\n",
    "    param_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss  = (out-100)**2\n",
    "\n",
    "loss.mean().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[587.2000, 587.2000, 587.2000,  ..., 587.2000, 587.2000, 587.2000],\n",
       "        [587.2000, 587.2000, 587.2000,  ..., 587.2000, 587.2000, 587.2000],\n",
       "        [587.2000, 587.2000, 587.2000,  ..., 587.2000, 587.2000, 587.2000],\n",
       "        ...,\n",
       "        [587.2000, 587.2000, 587.2000,  ..., 587.2000, 587.2000, 587.2000],\n",
       "        [587.2000, 587.2000, 587.2000,  ..., 587.2000, 587.2000, 587.2000],\n",
       "        [587.2000, 587.2000, 587.2000,  ..., 587.2000, 587.2000, 587.2000]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_list[0].grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "testnn_obj.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
