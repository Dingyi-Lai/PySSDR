{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from deepregression import Sddr_Single, Sddr\n",
    "from dataset import MyDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# todo\n",
    "\n",
    "sddr single:\n",
    "input to NN cannot be dicts\n",
    "\n",
    "\n",
    "SDDR: may be we make our own get_parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \n",
    "    family = \"poisson\"\n",
    "    \n",
    "    regularization_params = dict()\n",
    "    regularization_params[\"rate\"] = 1.   # already mutiplied in full_P\n",
    "    \n",
    "    deep_models_dict = {}\n",
    "    deep_shapes = {}\n",
    "    struct_shapes = 19\n",
    "    P = pd.read_csv (r'../example_data/simple_gam/full_P.csv',sep=';',header=None).values\n",
    "    \n",
    "    parsed_formula_contents = dict()\n",
    "    parsed_formula_contents[\"rate\"] = {\"deep_models_dict\": deep_models_dict, \"deep_shapes\": deep_shapes, \"struct_shapes\": struct_shapes, \"P\": P}\n",
    "    \n",
    "    x_path = r'../example_data/simple_gam/X.csv'\n",
    "    y_path = r'../example_data/simple_gam/Y.csv'\n",
    "    b_path = r'../example_data/simple_gam/B.csv'\n",
    "    \n",
    "    dataset = MyDataset(x_path, y_path, b_path)\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=1000,\n",
    "    )\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    bignet = Sddr(family, regularization_params, parsed_formula_contents)\n",
    "    bignet = bignet.to(device)\n",
    "    optimizer = optim.RMSprop(bignet.parameters())\n",
    "\n",
    "    bignet.train()\n",
    "    print('Begin training ...')\n",
    "    for epoch in range(1, 2500):\n",
    "\n",
    "        for batch in loader:\n",
    "            target = batch['target'].to(device)\n",
    "            meta_datadict = batch['meta_datadict']          # .to(device) should be improved \n",
    "            meta_datadict['rate']['structured'] = meta_datadict['rate']['structured'].to(device)\n",
    "            meta_datadict['rate']['dm1'] = meta_datadict['rate']['dm1'].to(device)\n",
    "           \n",
    "            optimizer.zero_grad()\n",
    "            output = bignet(meta_datadict)\n",
    "            loss = torch.mean(bignet.get_loss(target))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if epoch % 100 == 0:\n",
    "            print('Train Epoch: {} \\t Loss: {:.6f}'.format(epoch,loss.item()))\n",
    "            \n",
    "    return list(bignet.parameters())[0].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training ...\n",
      "Train Epoch: 100 \t Loss: 195.611206\n",
      "Train Epoch: 200 \t Loss: 2749.516357\n",
      "Train Epoch: 300 \t Loss: 2127.501465\n",
      "Train Epoch: 400 \t Loss: 1389.706909\n",
      "Train Epoch: 500 \t Loss: 1495.079102\n",
      "Train Epoch: 600 \t Loss: 1804.251343\n",
      "Train Epoch: 700 \t Loss: 1755.041138\n",
      "Train Epoch: 800 \t Loss: 1643.464966\n",
      "Train Epoch: 900 \t Loss: 1666.819458\n",
      "Train Epoch: 1000 \t Loss: 1706.623291\n",
      "Train Epoch: 1100 \t Loss: 1695.791504\n",
      "Train Epoch: 1200 \t Loss: 1681.843018\n",
      "Train Epoch: 1300 \t Loss: 1686.436646\n",
      "Train Epoch: 1400 \t Loss: 1691.247559\n",
      "Train Epoch: 1500 \t Loss: 1689.264038\n",
      "Train Epoch: 1600 \t Loss: 1687.595459\n",
      "Train Epoch: 1700 \t Loss: 1688.384521\n",
      "Train Epoch: 1800 \t Loss: 1688.920044\n",
      "Train Epoch: 1900 \t Loss: 1688.603882\n",
      "Train Epoch: 2000 \t Loss: 1688.394165\n",
      "Train Epoch: 2100 \t Loss: 1688.479370\n",
      "Train Epoch: 2200 \t Loss: 1688.600220\n",
      "Train Epoch: 2300 \t Loss: 1688.568848\n",
      "Train Epoch: 2400 \t Loss: 1688.479980\n"
     ]
    }
   ],
   "source": [
    "param = train()    # using adam optimizer can have smooth decreasing loss, using rmsprop the losses converge to a high value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.2963488   0.17352179  1.2300221   0.18499102  0.8007978  -0.3573757\n",
      "  -0.7536513  -0.31381568 -4.5485315   0.17799157  0.00499987 -0.00500003\n",
      "   0.00499975 -0.00500009  0.00500017 -0.0049999   0.00500004  0.00500005\n",
      "  -1.1238511 ]]\n"
     ]
    }
   ],
   "source": [
    "print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 1)\n"
     ]
    }
   ],
   "source": [
    "true_coeff = pd.read_csv (r'./example_data//simple_gam/true_coefficients.csv',sep=';',header=None).values\n",
    "B = pd.read_csv (r'./example_data//simple_gam/B.csv',sep=';',header=None).values\n",
    "X = pd.read_csv (r'./example_data/simple_gam/X.csv',sep=';',header=None).values\n",
    "print(true_coeff.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1)\n"
     ]
    }
   ],
   "source": [
    "hatY = np.matmul(B[:,1:10],true_coeff[1:10])\n",
    "print(hatY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_coeff = param\n",
    "pred_coeff = np.transpose(pred_coeff)\n",
    "\n",
    "hatY_pred = np.matmul(B[:,1:10],pred_coeff[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstCov = X[:,0] \n",
    "sortedHatY = [x for _,x in sorted(zip(firstCov,hatY))]\n",
    "sortedHatY_pred = [x for _,x in sorted(zip(firstCov,hatY_pred))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'PySDDR_coefficient')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(np.sort(firstCov), sortedHatY)\n",
    "plt.title('true_coefficient')\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(np.sort(firstCov), sortedHatY_pred)\n",
    "plt.title('PySDDR_coefficient')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test Sddr_Single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deep_shapes = {\"dm1\" : 5, \"dm2\" : 8}\n",
    "\n",
    "net2= nn.Sequential(nn.Linear(10,3),nn.ReLU(), nn.Linear(3,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_models_dict = {\"dm1\" : nn.Linear(10,5, bias = False), \"dm2\" : net2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct_shapes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.eye(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.ones(20,10)\n",
    "datadict = {\"structured\": data, \"dm1\": data, \"dm2\": data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = deepregression.Sddr_Single(deep_models_dict, deep_shapes, struct_shapes, P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(datadict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3598]], grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.get_regularization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1935,  0.0301, -0.0123,  0.0357, -0.2134, -0.0730, -0.0048, -0.2697,\n",
      "          0.0231, -0.2892],\n",
      "        [-0.3097, -0.1286,  0.0496, -0.0402,  0.1834,  0.2827,  0.1901, -0.0984,\n",
      "         -0.1785, -0.1594],\n",
      "        [ 0.2092, -0.2141,  0.1104, -0.1351,  0.1407, -0.0386, -0.2448, -0.3022,\n",
      "          0.1182,  0.1253],\n",
      "        [ 0.0958,  0.1131, -0.0343, -0.1154,  0.0705, -0.1790,  0.1225, -0.0100,\n",
      "          0.0172,  0.1540],\n",
      "        [-0.0907, -0.0408, -0.2554,  0.1053,  0.2946,  0.1850, -0.2062, -0.1011,\n",
      "         -0.2434, -0.2904]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0723, -0.3095,  0.2522, -0.2184, -0.3135,  0.1931,  0.0806,  0.1451,\n",
      "         -0.1344, -0.0403],\n",
      "        [ 0.0625, -0.2454,  0.2284,  0.1962,  0.1202, -0.1369, -0.0387, -0.1889,\n",
      "         -0.3157,  0.2815],\n",
      "        [-0.2833,  0.1714, -0.1251, -0.1508,  0.1746,  0.1788,  0.2207,  0.1514,\n",
      "          0.1758, -0.2217]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1996,  0.0521,  0.1826], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1985, -0.1477,  0.0056],\n",
      "        [ 0.5741,  0.1799,  0.2436],\n",
      "        [ 0.4924,  0.5052,  0.1599],\n",
      "        [-0.4921, -0.0860,  0.4233],\n",
      "        [-0.3430, -0.1013, -0.0256],\n",
      "        [ 0.3157,  0.5036, -0.0057],\n",
      "        [-0.2269,  0.0636,  0.4201],\n",
      "        [ 0.4668, -0.5302, -0.3753]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.4091,  0.4470, -0.0806,  0.4474,  0.2930,  0.0864,  0.3742,  0.2597],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.2501,  0.2258,  0.0919, -0.2480,  0.0470,  0.2709, -0.1401,  0.2031,\n",
      "         -0.1980, -0.0251]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 1.7300e-01, -7.1629e-02,  2.4312e-01,  2.2089e-01, -2.6441e-01,\n",
      "         -2.1641e-01,  1.6032e-01,  2.3320e-04, -1.4924e-02,  9.4535e-02,\n",
      "         -8.4762e-02,  1.3740e-01, -8.4525e-02]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in net.parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.6698, -0.1423],\n",
      "        [ 0.5038,  0.0981],\n",
      "        [-0.1744, -0.1339],\n",
      "        [-0.4113,  0.3310],\n",
      "        [-0.4738, -0.2220]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1450,  0.1367,  0.1768,  0.1635, -0.0770,  0.1613, -0.0192,  0.0786,\n",
      "         -0.2005, -0.2166, -0.2112,  0.0377,  0.0462,  0.1035,  0.1268, -0.0238,\n",
      "          0.0126, -0.0916,  0.1823]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1046,  0.2764, -0.3203, -0.0709,  0.2124]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in bignet.parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Sddr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [],
   "source": [
    "family= \"normal\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parsed_formula_contents = dict()\n",
    "parsed_formula_contents[\"loc\"] = {\"deep_models_dict\": deep_models_dict, \"deep_shapes\": deep_shapes, \"struct_shapes\": struct_shapes, \"P\": P}\n",
    "parsed_formula_contents[\"scale\"] = {\"deep_models_dict\": dict(), \"deep_shapes\": dict(), \"struct_shapes\": struct_shapes, \"P\": P}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularization_params = dict()\n",
    "\n",
    "regularization_params[\"loc\"] = 1.\n",
    "regularization_params[\"scale\"] = 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_datadict = dict()\n",
    "\n",
    "'''\n",
    "formulas = dict()\n",
    "\n",
    "formulas['loc'] = '1 + s(x1) + s(x2) + d(x1) + d(x2)'\n",
    "'\n",
    "formulas['scale'] = '1 + s(x)' \n",
    "\n",
    "meta_datadict = parse_formulas(formulas, data)\n",
    "        \n",
    "'''\n",
    "\n",
    "meta_datadict[\"loc\"] = datadict # datadict = {\"structured\": data, \"dm1\": data, \"dm2\": data}\n",
    "meta_datadict[\"scale\"] = {\"structured\": data}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [],
   "source": [
    "bignet = deepregression.Sddr(family, regularization_params, parsed_formula_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loc\n",
      "scale\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Normal(loc: torch.Size([20, 1]), scale: torch.Size([20, 1]))"
      ]
     },
     "execution_count": 843,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bignet(meta_datadict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sddr_Single(\n",
      "  (dm1): Linear(in_features=10, out_features=5, bias=False)\n",
      "  (dm2): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=3, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=3, out_features=8, bias=True)\n",
      "  )\n",
      "  (structured_head): Linear(in_features=10, out_features=1, bias=False)\n",
      "  (deep_head): Linear(in_features=13, out_features=1, bias=False)\n",
      ")\n",
      "Sddr_Single(\n",
      "  (structured_head): Linear(in_features=10, out_features=1, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for i in bignet.children():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0450,  0.3132, -0.2533, -0.0663,  0.1513,  0.1618, -0.1711,  0.1751,\n",
      "          0.2034, -0.1013],\n",
      "        [ 0.1457, -0.1887,  0.1578, -0.0177, -0.0884, -0.2482,  0.1933,  0.1885,\n",
      "          0.1223,  0.1456],\n",
      "        [-0.2872,  0.2873,  0.0221,  0.1267, -0.1926, -0.1228, -0.1013, -0.3115,\n",
      "         -0.1070,  0.3092],\n",
      "        [ 0.2323, -0.0799,  0.2225,  0.0531,  0.0059,  0.1509, -0.1401,  0.2687,\n",
      "          0.1905, -0.2308],\n",
      "        [-0.0035, -0.1833, -0.1211, -0.0225, -0.2246,  0.0049, -0.0644, -0.2636,\n",
      "         -0.1963, -0.2150]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1504,  0.0733, -0.0326,  0.1949, -0.0519, -0.0607, -0.0694,  0.0783,\n",
      "         -0.2417, -0.0261],\n",
      "        [-0.2603, -0.0073,  0.2344, -0.2413, -0.1986, -0.1428, -0.2594,  0.0118,\n",
      "         -0.1722,  0.1692],\n",
      "        [ 0.0141, -0.2903,  0.2476, -0.2810, -0.0929, -0.2952,  0.1316, -0.0939,\n",
      "          0.1434, -0.0977]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.2397, 0.1327, 0.1444], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0546, -0.4211, -0.0831],\n",
      "        [-0.4595, -0.5765,  0.0705],\n",
      "        [-0.3481,  0.2289,  0.0538],\n",
      "        [ 0.4195,  0.3138, -0.3943],\n",
      "        [ 0.0446, -0.0511, -0.4801],\n",
      "        [-0.2535, -0.4461, -0.2677],\n",
      "        [-0.4290,  0.4814, -0.0919],\n",
      "        [-0.1165,  0.1927,  0.2213]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.5256,  0.3756,  0.1480,  0.2058,  0.5054, -0.1609,  0.4523,  0.0451],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1032, -0.2826,  0.2035,  0.0458,  0.1571, -0.0421, -0.2679,  0.3128,\n",
      "         -0.2690,  0.0560]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1785, -0.1413,  0.2162, -0.1403, -0.0686, -0.1385, -0.2135,  0.0126,\n",
      "         -0.0471, -0.1484,  0.2358, -0.1200,  0.1646]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1944, -0.1053, -0.2871, -0.0242, -0.0027,  0.2059,  0.0305,  0.2846,\n",
      "          0.0894, -0.0680]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in bignet.parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = torch.ones([20,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1])"
      ]
     },
     "execution_count": 847,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = bignet.get_loss(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.mean().backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing for dictionary as input to neural network module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class testnn(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(testnn, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.weights = nn.Parameter(torch.ones(784, 10) )\n",
    "        self.bias = nn.Parameter(torch.zeros(10))\n",
    "\n",
    "    def forward(self, xa):\n",
    "        #xa = datadict[\"a\"]\n",
    "        #xb = datadict[\"b\"]\n",
    "        out = xa @ self.weights + xa @ self.weights + self.bias\n",
    "        return out\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "testnn_obj = testnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.ones([784,10]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = testnn_obj(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_list = []\n",
    "for i in testnn_obj.parameters():\n",
    "    param_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss  = (out-100)**2\n",
    "\n",
    "loss.mean().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[587.2000, 587.2000, 587.2000,  ..., 587.2000, 587.2000, 587.2000],\n",
       "        [587.2000, 587.2000, 587.2000,  ..., 587.2000, 587.2000, 587.2000],\n",
       "        [587.2000, 587.2000, 587.2000,  ..., 587.2000, 587.2000, 587.2000],\n",
       "        ...,\n",
       "        [587.2000, 587.2000, 587.2000,  ..., 587.2000, 587.2000, 587.2000],\n",
       "        [587.2000, 587.2000, 587.2000,  ..., 587.2000, 587.2000, 587.2000],\n",
       "        [587.2000, 587.2000, 587.2000,  ..., 587.2000, 587.2000, 587.2000]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_list[0].grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "testnn_obj.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This code can be found in deepregression.py and dataset.py so should not be used here so we only make changes to one code and don't get confused. Remove after checking with others that it is exact duplicate ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Sddr_Single(nn.Module):\n",
    "    \n",
    "    def __init__(self, deep_models_dict, deep_shapes, struct_shapes, P):\n",
    "        \"\"\"\n",
    "        deep_models_dict: dictionary where key are names of deep models and values are objects that define the deep models\n",
    "        struct_shapes: number of structural features\n",
    "        P: numpy matrix for the smoothing regularization (with added zero matrix in the beginning for the linear part)\n",
    "        \n",
    "        \"\"\"\n",
    "        super(Sddr_Single, self).__init__()\n",
    "        self.P = P\n",
    "        self.deep_models_dict = deep_models_dict\n",
    "        \n",
    "        #register external neural networks\n",
    "        for key, value in deep_models_dict.items():\n",
    "            self.add_module(key,value)\n",
    "        \n",
    "        \n",
    "        self.structured_head = nn.Linear(struct_shapes,1, bias = False)\n",
    "        \n",
    "        if len(deep_models_dict) != 0:\n",
    "            output_size_of_deep_models  = sum([deep_shapes[key] for key in deep_shapes.keys()])\n",
    "            self.deep_head = nn.Linear(output_size_of_deep_models,1, bias = False)\n",
    "            self._deep_models_exist = True\n",
    "        else:\n",
    "            self._deep_models_exist = False\n",
    "        \n",
    "              \n",
    "        \n",
    "    def _orthog_layer(self, Q, Uhat):\n",
    "        \"\"\"\n",
    "        Utilde = Uhat - QQTUhat\n",
    "        \"\"\"\n",
    "        print(Q)\n",
    "        print(Q.T)\n",
    "        Projection_Matrix = Q @ Q.T\n",
    "        print(Projection_Matrix)\n",
    "        Utilde = Uhat - Projection_Matrix @ Uhat\n",
    "        \n",
    "        return Utilde\n",
    "    \n",
    "    \n",
    "    def forward(self, datadict):\n",
    "        \"\"\"Comment 6.8.2020 We checked that we can actually have a dictionary as an input here. that should work fine\"\"\"\n",
    "        \n",
    "        X = datadict[\"structured\"]\n",
    "        \n",
    "        if self._deep_models_exist:\n",
    "            Q, R = torch.qr(X)\n",
    "\n",
    "            Uhat_list = []\n",
    "            for key in self.deep_models_dict.keys(): #assume that the input for the NN has the name of the NN as key\n",
    "                net = self.deep_models_dict[key]\n",
    "                Uhat_list.append(net(datadict[key]))\n",
    "            \n",
    "            Uhat = torch.cat(Uhat_list, dim = 1) #concatenate the outputs of the deep NNs\n",
    "\n",
    "            Utilde = self._orthog_layer(Q, Uhat)\n",
    "            \n",
    "            deep_pred = self.deep_head(Utilde)\n",
    "        else:\n",
    "            deep_pred = 0\n",
    "        \n",
    "        structured_pred = self.structured_head(X)\n",
    "        \n",
    "        pred = structured_pred + deep_pred\n",
    "        \n",
    "        return pred\n",
    "    \n",
    "    def get_regularization(self):\n",
    "        P = torch.from_numpy(self.P).float() # should have shape struct_shapes x struct_shapes, numpy array\n",
    "        weights = self.structured_head.weight #should have shape 1 x struct_shapes\n",
    "        \n",
    "        \n",
    "        regularization = weights @ P @ weights.T\n",
    "        \n",
    "        return regularization\n",
    "        \n",
    "        \n",
    "        \n",
    "class Sddr(nn.Module):\n",
    "    \n",
    "    def __init__(self, family, regularization_params, parsed_formula_contents):\n",
    "        \"\"\"\n",
    "        family: string e.g. \"gaussian\", \"binomial\"...\n",
    "        regularization_params: smoothing parameters\n",
    "        parsed_formula_contents: dictionary with keys being parameters of the distribution, e.g. \"eta\" and \"scale\"\n",
    "        and values being dicts with keys deep_models_dict, struct_shapes and P (as used in Sddr_Single)\n",
    "        \"\"\"\n",
    "        super(Sddr, self).__init__()\n",
    "        self.family = family\n",
    "        self.regularization_params = regularization_params\n",
    "        self.parameter_names = parsed_formula_contents.keys\n",
    "        self.single_parameter_sddr_list = dict()\n",
    "        for key, value in parsed_formula_contents.items():\n",
    "            deep_models_dict = value[\"deep_models_dict\"]\n",
    "            deep_shapes = value[\"deep_shapes\"]\n",
    "            struct_shapes = value[\"struct_shapes\"]\n",
    "            P = value[\"P\"]\n",
    "            self.single_parameter_sddr_list[key] = Sddr_Single(deep_models_dict, deep_shapes, struct_shapes, P)\n",
    "            \n",
    "            #register the Sddr_Single network\n",
    "            self.add_module(key,self.single_parameter_sddr_list[key])\n",
    "                \n",
    "\n",
    "        #define distributional layer\n",
    "        if family == \"normal\":\n",
    "            self.distribution_layer_type = torch.distributions.normal.Normal\n",
    "        elif family == \"poisson\":\n",
    "            self.distribution_layer_type = torch.distributions.poisson.Poisson\n",
    "    \n",
    "    def _distribution_trafos(self,pred):\n",
    "        #applies the specific transformations to the prediction so they they correspond to the restrictions\n",
    "        #of the parameters\n",
    "        #this is family specific\n",
    "        pred_trafo = dict()\n",
    "        add_const = 1e-8\n",
    "        \n",
    "        family = self.family\n",
    "        if family == \"normal\":\n",
    "            pred_trafo[\"loc\"] = pred[\"loc\"]\n",
    "            pred_trafo[\"scale\"] = add_const + pred[\"scale\"].exp()\n",
    "        elif family == \"poisson\":\n",
    "            pred_trafo[\"rate\"] = add_const + pred[\"rate\"].exp()\n",
    "        \n",
    "        return pred_trafo\n",
    "    \n",
    "    def forward(self,meta_datadict):\n",
    "        \n",
    "        self.regul = 0\n",
    "        pred = dict()\n",
    "        for parameter_name, data_dict  in meta_datadict.items():\n",
    "            sddr_net = self.single_parameter_sddr_list[parameter_name]\n",
    "            pred[parameter_name] = sddr_net(data_dict)\n",
    "            self.regul += sddr_net.get_regularization()*self.regularization_params[parameter_name]\n",
    "            \n",
    "        predicted_parameters = self._distribution_trafos(pred)\n",
    "        \n",
    "        #define distributional layer (takes eta and scale)\n",
    "        self.distribution_layer = self.distribution_layer_type(**predicted_parameters)\n",
    "        \n",
    "        return self.distribution_layer\n",
    "    \n",
    "    def get_loss(self, Y):\n",
    "    \n",
    "#         regul = 0            # move to forward, or we need meta_datadict as input to get_loss\n",
    "#         for parameter_name, data_dict  in meta_datadict.items():\n",
    "#             sddr_net = self.single_parameter_sddr_list[parameter_name]\n",
    "#             regul += sddr_net.get_regularization()*self.regularization_params[parameter_name]\n",
    "        log_loss = -self.distribution_layer.log_prob(Y)\n",
    "        loss = log_loss + self.regul\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        x_csv = pd.read_csv (r'./example_data/simple_gam/X.csv',sep=';',header=None)\n",
    "        y_csv = pd.read_csv (r'./example_data/simple_gam/Y.csv',header=None)\n",
    "        B_csv = pd.read_csv (r'./example_data/simple_gam/B.csv',sep=';',header=None)\n",
    "        \n",
    "        self.struct_data = torch.from_numpy(B_csv.values).float()\n",
    "        self.deep_data = torch.from_numpy(x_csv.values).float()\n",
    "        self.y = torch.from_numpy(y_csv.values).float()\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        struct = self.struct_data[index]\n",
    "        deep = self.deep_data[index]\n",
    "        gt = self.y[index]\n",
    "        \n",
    "        datadict = {\"structured\": struct, \"dm1\": deep}\n",
    "        meta_datadict = dict()\n",
    "        meta_datadict[\"rate\"] = datadict\n",
    "        \n",
    "        return {'meta_datadict': meta_datadict, 'target': gt}        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.deep_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
