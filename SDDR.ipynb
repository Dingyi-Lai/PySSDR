{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Sddr_Single' from 'deepregression' (/Users/christina.bukas/Documents/AI_projects/code/reimplementations/PySDDR/deepregression.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f82adc6b6589>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepregression\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSddr_Single\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSddr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMyDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Sddr_Single' from 'deepregression' (/Users/christina.bukas/Documents/AI_projects/code/reimplementations/PySDDR/deepregression.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from deepregression import Sddr_Single, Sddr\n",
    "from dataset import MyDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# todo\n",
    "\n",
    "sddr single:\n",
    "input to NN cannot be dicts\n",
    "\n",
    "\n",
    "SDDR: may be we make our own get_parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \n",
    "    cur_distribution = \"poisson\"\n",
    "    family = {'normal':{'loc': 'whateva', 'scale': 'whateva2'}, 'poisson': {'rate': 'whateva'}, 'binomial':{'n': 'whateva', 'p': 'whateva'}}\n",
    "    \n",
    "    regularization_params = dict()\n",
    "    regularization_params[\"rate\"] = 1.   # already mutiplied in full_P\n",
    "        \n",
    "    x_path = r'./example_data/simple_gam/X.csv'\n",
    "    y_path = r'./example_data/simple_gam/Y.csv'\n",
    "    \n",
    "    formulas = dict()\n",
    "    formulas['rate'] = '~1+spline(x1, bs=\"bs\",df=9)+spline(x2, bs=\"bs\",df=9)+d1(x1)+d2(x2)'\n",
    "    \n",
    "    deep_models_dict = dict()\n",
    "    deep_models_dict['rate'] = dict()\n",
    "    deep_models_dict['rate']['d1'] = nn.Sequential(nn.Linear(1,15))\n",
    "    deep_models_dict['rate']['d2'] = nn.Sequential(nn.Linear(1,3),nn.ReLU(), nn.Linear(3,8))\n",
    "    \n",
    "    deep_shapes = dict()\n",
    "    deep_shapes['rate'] = {\"d1\" : 15, \"d2\" : 8}\n",
    "    \n",
    "    \n",
    "    dataset = MyDataset(x_path, y_path,family, formulas,cur_distribution, deep_models_dict,deep_shapes)\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=1000,\n",
    "    )\n",
    "    parsed_formula_contents = dataset.get_parsed_formula_content()\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    bignet = Sddr(cur_distribution, regularization_params, parsed_formula_contents)\n",
    "    bignet = bignet.to(device)\n",
    "    optimizer = optim.RMSprop(bignet.parameters())\n",
    "\n",
    "    bignet.train()\n",
    "    print('Begin training ...')\n",
    "    for epoch in range(1, 2500): \n",
    "\n",
    "        for batch in loader:\n",
    "            target = batch['target'].to(device)\n",
    "            meta_datadict = batch['meta_datadict']          # .to(device) should be improved \n",
    "            meta_datadict['rate']['structured'] = meta_datadict['rate']['structured'].to(device)\n",
    "            meta_datadict['rate']['d1'] = meta_datadict['rate']['d1'].to(device)\n",
    "           \n",
    "            optimizer.zero_grad()\n",
    "            output = bignet(meta_datadict)\n",
    "            loss = torch.mean(bignet.get_loss(target))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if epoch % 100 == 0:\n",
    "            print('Train Epoch: {} \\t Loss: {:.6f}'.format(epoch,loss.item()))\n",
    "    for param in bignet.parameters():\n",
    "        print(param.size())\n",
    "    return list(bignet.parameters())[-2].detach().numpy(), meta_datadict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results from split formula\n",
      "1+spline(x1,bs=\"bs\",df=9)+spline(x2,bs=\"bs\",df=9)\n",
      "['d1(x1)', 'd2(x2)']\n",
      "Begin training ...\n",
      "Train Epoch: 100 \t Loss: 23.097507\n",
      "Train Epoch: 200 \t Loss: 11.804540\n",
      "Train Epoch: 300 \t Loss: 10.777796\n",
      "Train Epoch: 400 \t Loss: 10.657060\n",
      "Train Epoch: 500 \t Loss: 10.623084\n",
      "Train Epoch: 600 \t Loss: 10.618132\n",
      "Train Epoch: 700 \t Loss: 10.630344\n",
      "Train Epoch: 800 \t Loss: 10.621990\n",
      "Train Epoch: 900 \t Loss: 10.618189\n",
      "Train Epoch: 1000 \t Loss: 10.620993\n",
      "Train Epoch: 1100 \t Loss: 10.622469\n",
      "Train Epoch: 1200 \t Loss: 10.621264\n",
      "Train Epoch: 1300 \t Loss: 10.620602\n",
      "Train Epoch: 1400 \t Loss: 10.621006\n",
      "Train Epoch: 1500 \t Loss: 10.620811\n",
      "Train Epoch: 1600 \t Loss: 10.620588\n",
      "Train Epoch: 1700 \t Loss: 10.620577\n",
      "Train Epoch: 1800 \t Loss: 10.620593\n",
      "Train Epoch: 1900 \t Loss: 10.620001\n",
      "Train Epoch: 2000 \t Loss: 10.620045\n",
      "Train Epoch: 2100 \t Loss: 10.619385\n",
      "Train Epoch: 2200 \t Loss: 10.619472\n",
      "Train Epoch: 2300 \t Loss: 10.619110\n",
      "Train Epoch: 2400 \t Loss: 10.619228\n",
      "torch.Size([15, 1])\n",
      "torch.Size([15])\n",
      "torch.Size([3, 1])\n",
      "torch.Size([3])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8])\n",
      "torch.Size([1, 19])\n",
      "torch.Size([1, 23])\n"
     ]
    }
   ],
   "source": [
    "param, meta_datadict = train()    # using adam optimizer can have smooth decreasing loss, using rmsprop the losses converge to a high value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 19)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_aut = meta_datadict['rate']['structured'].detach().numpy()\n",
    "b_aut.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       8.2510240e-02, 6.2818539e-01, 2.8843054e-01, 8.7381050e-04,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.4295752e-03,\n",
       "       7.4673563e-02, 4.8595178e-01, 4.3694505e-01], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_aut[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.083787  ,  1.9523523 ,  1.473148  ,  0.5059978 , -0.5328081 ,\n",
       "        -0.86177635, -0.50600684,  0.4328535 ,  1.3415076 ,  1.854659  ,\n",
       "         2.3974814 ,  2.170725  ,  1.7714853 ,  1.1269901 ,  0.4804498 ,\n",
       "        -0.16591364, -0.8464178 , -1.3247423 , -1.5499686 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 1)\n"
     ]
    }
   ],
   "source": [
    "true_coeff = pd.read_csv (r'example_data/simple_gam/true_coefficients.csv',sep=';',header=None).values\n",
    "B = pd.read_csv (r'example_data/simple_gam/B.csv',sep=';',header=None).values\n",
    "#B = pd.read_csv (r'B_gen.csv',sep=';',header=None).values\n",
    "#B=B[:,1:]\n",
    "X = pd.read_csv (r'../example_data/simple_gam/X.csv',sep=';',header=None).values\n",
    "print(true_coeff.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(meta_datadict['rate']['structured'].size() == B.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_coeff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "hatY = np.matmul(B[:,1:10],true_coeff[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 1)\n"
     ]
    }
   ],
   "source": [
    "pred_coeff = param\n",
    "pred_coeff = np.transpose(pred_coeff)\n",
    "print(pred_coeff.shape)\n",
    "hatY_pred = np.matmul(b_aut[:,1:10],pred_coeff[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstCov = X[:,0] \n",
    "sortedHatY = [x for _,x in sorted(zip(firstCov,hatY))]\n",
    "sortedHatY_pred = [x for _,x in sorted(zip(firstCov,hatY_pred))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'PySDDR_coefficient')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(np.sort(firstCov), sortedHatY)\n",
    "plt.title('true_coefficient')\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(np.sort(firstCov), sortedHatY_pred)\n",
    "plt.title('PySDDR_coefficient')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test Sddr_Single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deep_shapes = {\"dm1\" : 5, \"dm2\" : 8}\n",
    "\n",
    "net2= nn.Sequential(nn.Linear(10,3),nn.ReLU(), nn.Linear(3,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_models_dict = {\"dm1\" : nn.Linear(10,5, bias = False), \"dm2\" : net2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct_shapes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.eye(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.ones(20,10)\n",
    "datadict = {\"structured\": data, \"dm1\": data, \"dm2\": data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = deepregression.Sddr_Single(deep_models_dict, deep_shapes, struct_shapes, P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(datadict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3598]], grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.get_regularization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1935,  0.0301, -0.0123,  0.0357, -0.2134, -0.0730, -0.0048, -0.2697,\n",
      "          0.0231, -0.2892],\n",
      "        [-0.3097, -0.1286,  0.0496, -0.0402,  0.1834,  0.2827,  0.1901, -0.0984,\n",
      "         -0.1785, -0.1594],\n",
      "        [ 0.2092, -0.2141,  0.1104, -0.1351,  0.1407, -0.0386, -0.2448, -0.3022,\n",
      "          0.1182,  0.1253],\n",
      "        [ 0.0958,  0.1131, -0.0343, -0.1154,  0.0705, -0.1790,  0.1225, -0.0100,\n",
      "          0.0172,  0.1540],\n",
      "        [-0.0907, -0.0408, -0.2554,  0.1053,  0.2946,  0.1850, -0.2062, -0.1011,\n",
      "         -0.2434, -0.2904]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0723, -0.3095,  0.2522, -0.2184, -0.3135,  0.1931,  0.0806,  0.1451,\n",
      "         -0.1344, -0.0403],\n",
      "        [ 0.0625, -0.2454,  0.2284,  0.1962,  0.1202, -0.1369, -0.0387, -0.1889,\n",
      "         -0.3157,  0.2815],\n",
      "        [-0.2833,  0.1714, -0.1251, -0.1508,  0.1746,  0.1788,  0.2207,  0.1514,\n",
      "          0.1758, -0.2217]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1996,  0.0521,  0.1826], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1985, -0.1477,  0.0056],\n",
      "        [ 0.5741,  0.1799,  0.2436],\n",
      "        [ 0.4924,  0.5052,  0.1599],\n",
      "        [-0.4921, -0.0860,  0.4233],\n",
      "        [-0.3430, -0.1013, -0.0256],\n",
      "        [ 0.3157,  0.5036, -0.0057],\n",
      "        [-0.2269,  0.0636,  0.4201],\n",
      "        [ 0.4668, -0.5302, -0.3753]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.4091,  0.4470, -0.0806,  0.4474,  0.2930,  0.0864,  0.3742,  0.2597],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.2501,  0.2258,  0.0919, -0.2480,  0.0470,  0.2709, -0.1401,  0.2031,\n",
      "         -0.1980, -0.0251]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 1.7300e-01, -7.1629e-02,  2.4312e-01,  2.2089e-01, -2.6441e-01,\n",
      "         -2.1641e-01,  1.6032e-01,  2.3320e-04, -1.4924e-02,  9.4535e-02,\n",
      "         -8.4762e-02,  1.3740e-01, -8.4525e-02]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in net.parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.6698, -0.1423],\n",
      "        [ 0.5038,  0.0981],\n",
      "        [-0.1744, -0.1339],\n",
      "        [-0.4113,  0.3310],\n",
      "        [-0.4738, -0.2220]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1450,  0.1367,  0.1768,  0.1635, -0.0770,  0.1613, -0.0192,  0.0786,\n",
      "         -0.2005, -0.2166, -0.2112,  0.0377,  0.0462,  0.1035,  0.1268, -0.0238,\n",
      "          0.0126, -0.0916,  0.1823]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1046,  0.2764, -0.3203, -0.0709,  0.2124]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in bignet.parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Sddr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [],
   "source": [
    "family= \"normal\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parsed_formula_contents = dict()\n",
    "parsed_formula_contents[\"loc\"] = {\"deep_models_dict\": deep_models_dict, \"deep_shapes\": deep_shapes, \"struct_shapes\": struct_shapes, \"P\": P}\n",
    "parsed_formula_contents[\"scale\"] = {\"deep_models_dict\": dict(), \"deep_shapes\": dict(), \"struct_shapes\": struct_shapes, \"P\": P}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularization_params = dict()\n",
    "\n",
    "regularization_params[\"loc\"] = 1.\n",
    "regularization_params[\"scale\"] = 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_datadict = dict()\n",
    "\n",
    "'''\n",
    "formulas = dict()\n",
    "\n",
    "formulas['loc'] = '1 + s(x1) + s(x2) + d(x1) + d(x2)'\n",
    "'\n",
    "formulas['scale'] = '1 + s(x)' \n",
    "\n",
    "meta_datadict = parse_formulas(formulas, data)\n",
    "        \n",
    "'''\n",
    "\n",
    "meta_datadict[\"loc\"] = datadict # datadict = {\"structured\": data, \"dm1\": data, \"dm2\": data}\n",
    "meta_datadict[\"scale\"] = {\"structured\": data}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [],
   "source": [
    "bignet = deepregression.Sddr(family, regularization_params, parsed_formula_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loc\n",
      "scale\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Normal(loc: torch.Size([20, 1]), scale: torch.Size([20, 1]))"
      ]
     },
     "execution_count": 843,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bignet(meta_datadict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sddr_Single(\n",
      "  (dm1): Linear(in_features=10, out_features=5, bias=False)\n",
      "  (dm2): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=3, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=3, out_features=8, bias=True)\n",
      "  )\n",
      "  (structured_head): Linear(in_features=10, out_features=1, bias=False)\n",
      "  (deep_head): Linear(in_features=13, out_features=1, bias=False)\n",
      ")\n",
      "Sddr_Single(\n",
      "  (structured_head): Linear(in_features=10, out_features=1, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for i in bignet.children():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0450,  0.3132, -0.2533, -0.0663,  0.1513,  0.1618, -0.1711,  0.1751,\n",
      "          0.2034, -0.1013],\n",
      "        [ 0.1457, -0.1887,  0.1578, -0.0177, -0.0884, -0.2482,  0.1933,  0.1885,\n",
      "          0.1223,  0.1456],\n",
      "        [-0.2872,  0.2873,  0.0221,  0.1267, -0.1926, -0.1228, -0.1013, -0.3115,\n",
      "         -0.1070,  0.3092],\n",
      "        [ 0.2323, -0.0799,  0.2225,  0.0531,  0.0059,  0.1509, -0.1401,  0.2687,\n",
      "          0.1905, -0.2308],\n",
      "        [-0.0035, -0.1833, -0.1211, -0.0225, -0.2246,  0.0049, -0.0644, -0.2636,\n",
      "         -0.1963, -0.2150]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1504,  0.0733, -0.0326,  0.1949, -0.0519, -0.0607, -0.0694,  0.0783,\n",
      "         -0.2417, -0.0261],\n",
      "        [-0.2603, -0.0073,  0.2344, -0.2413, -0.1986, -0.1428, -0.2594,  0.0118,\n",
      "         -0.1722,  0.1692],\n",
      "        [ 0.0141, -0.2903,  0.2476, -0.2810, -0.0929, -0.2952,  0.1316, -0.0939,\n",
      "          0.1434, -0.0977]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.2397, 0.1327, 0.1444], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0546, -0.4211, -0.0831],\n",
      "        [-0.4595, -0.5765,  0.0705],\n",
      "        [-0.3481,  0.2289,  0.0538],\n",
      "        [ 0.4195,  0.3138, -0.3943],\n",
      "        [ 0.0446, -0.0511, -0.4801],\n",
      "        [-0.2535, -0.4461, -0.2677],\n",
      "        [-0.4290,  0.4814, -0.0919],\n",
      "        [-0.1165,  0.1927,  0.2213]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.5256,  0.3756,  0.1480,  0.2058,  0.5054, -0.1609,  0.4523,  0.0451],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1032, -0.2826,  0.2035,  0.0458,  0.1571, -0.0421, -0.2679,  0.3128,\n",
      "         -0.2690,  0.0560]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1785, -0.1413,  0.2162, -0.1403, -0.0686, -0.1385, -0.2135,  0.0126,\n",
      "         -0.0471, -0.1484,  0.2358, -0.1200,  0.1646]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1944, -0.1053, -0.2871, -0.0242, -0.0027,  0.2059,  0.0305,  0.2846,\n",
      "          0.0894, -0.0680]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in bignet.parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = torch.ones([20,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1])"
      ]
     },
     "execution_count": 847,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = bignet.get_loss(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.mean().backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing for dictionary as input to neural network module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class testnn(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(testnn, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.weights = nn.Parameter(torch.ones(784, 10) )\n",
    "        self.bias = nn.Parameter(torch.zeros(10))\n",
    "\n",
    "    def forward(self, xa):\n",
    "        #xa = datadict[\"a\"]\n",
    "        #xb = datadict[\"b\"]\n",
    "        out = xa @ self.weights + xa @ self.weights + self.bias\n",
    "        return out\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "testnn_obj = testnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.ones([784,10]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = testnn_obj(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_list = []\n",
    "for i in testnn_obj.parameters():\n",
    "    param_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss  = (out-100)**2\n",
    "\n",
    "loss.mean().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[587.2000, 587.2000, 587.2000,  ..., 587.2000, 587.2000, 587.2000],\n",
       "        [587.2000, 587.2000, 587.2000,  ..., 587.2000, 587.2000, 587.2000],\n",
       "        [587.2000, 587.2000, 587.2000,  ..., 587.2000, 587.2000, 587.2000],\n",
       "        ...,\n",
       "        [587.2000, 587.2000, 587.2000,  ..., 587.2000, 587.2000, 587.2000],\n",
       "        [587.2000, 587.2000, 587.2000,  ..., 587.2000, 587.2000, 587.2000],\n",
       "        [587.2000, 587.2000, 587.2000,  ..., 587.2000, 587.2000, 587.2000]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_list[0].grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "testnn_obj.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This code can be found in deepregression.py and dataset.py so should not be used here so we only make changes to one code and don't get confused. Remove after checking with others that it is exact duplicate ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Sddr_Single(nn.Module):\n",
    "    \n",
    "    def __init__(self, deep_models_dict, deep_shapes, struct_shapes, P):\n",
    "        \"\"\"\n",
    "        deep_models_dict: dictionary where key are names of deep models and values are objects that define the deep models\n",
    "        struct_shapes: number of structural features\n",
    "        P: numpy matrix for the smoothing regularization (with added zero matrix in the beginning for the linear part)\n",
    "        \n",
    "        \"\"\"\n",
    "        super(Sddr_Single, self).__init__()\n",
    "        self.P = P\n",
    "        self.deep_models_dict = deep_models_dict\n",
    "        \n",
    "        #register external neural networks\n",
    "        for key, value in deep_models_dict.items():\n",
    "            self.add_module(key,value)\n",
    "        \n",
    "        \n",
    "        self.structured_head = nn.Linear(struct_shapes,1, bias = False)\n",
    "        \n",
    "        if len(deep_models_dict) != 0:\n",
    "            output_size_of_deep_models  = sum([deep_shapes[key] for key in deep_shapes.keys()])\n",
    "            self.deep_head = nn.Linear(output_size_of_deep_models,1, bias = False)\n",
    "            self._deep_models_exist = True\n",
    "        else:\n",
    "            self._deep_models_exist = False\n",
    "        \n",
    "              \n",
    "        \n",
    "    def _orthog_layer(self, Q, Uhat):\n",
    "        \"\"\"\n",
    "        Utilde = Uhat - QQTUhat\n",
    "        \"\"\"\n",
    "        print(Q)\n",
    "        print(Q.T)\n",
    "        Projection_Matrix = Q @ Q.T\n",
    "        print(Projection_Matrix)\n",
    "        Utilde = Uhat - Projection_Matrix @ Uhat\n",
    "        \n",
    "        return Utilde\n",
    "    \n",
    "    \n",
    "    def forward(self, datadict):\n",
    "        \"\"\"Comment 6.8.2020 We checked that we can actually have a dictionary as an input here. that should work fine\"\"\"\n",
    "        \n",
    "        X = datadict[\"structured\"]\n",
    "        \n",
    "        if self._deep_models_exist:\n",
    "            Q, R = torch.qr(X)\n",
    "\n",
    "            Uhat_list = []\n",
    "            for key in self.deep_models_dict.keys(): #assume that the input for the NN has the name of the NN as key\n",
    "                net = self.deep_models_dict[key]\n",
    "                Uhat_list.append(net(datadict[key]))\n",
    "            \n",
    "            Uhat = torch.cat(Uhat_list, dim = 1) #concatenate the outputs of the deep NNs\n",
    "\n",
    "            Utilde = self._orthog_layer(Q, Uhat)\n",
    "            \n",
    "            deep_pred = self.deep_head(Utilde)\n",
    "        else:\n",
    "            deep_pred = 0\n",
    "        \n",
    "        structured_pred = self.structured_head(X)\n",
    "        \n",
    "        pred = structured_pred + deep_pred\n",
    "        \n",
    "        return pred\n",
    "    \n",
    "    def get_regularization(self):\n",
    "        P = torch.from_numpy(self.P).float() # should have shape struct_shapes x struct_shapes, numpy array\n",
    "        weights = self.structured_head.weight #should have shape 1 x struct_shapes\n",
    "        \n",
    "        \n",
    "        regularization = weights @ P @ weights.T\n",
    "        \n",
    "        return regularization\n",
    "        \n",
    "        \n",
    "        \n",
    "class Sddr(nn.Module):\n",
    "    \n",
    "    def __init__(self, family, regularization_params, parsed_formula_contents):\n",
    "        \"\"\"\n",
    "        family: string e.g. \"gaussian\", \"binomial\"...\n",
    "        regularization_params: smoothing parameters\n",
    "        parsed_formula_contents: dictionary with keys being parameters of the distribution, e.g. \"eta\" and \"scale\"\n",
    "        and values being dicts with keys deep_models_dict, struct_shapes and P (as used in Sddr_Single)\n",
    "        \"\"\"\n",
    "        super(Sddr, self).__init__()\n",
    "        self.family = family\n",
    "        self.regularization_params = regularization_params\n",
    "        self.parameter_names = parsed_formula_contents.keys\n",
    "        self.single_parameter_sddr_list = dict()\n",
    "        for key, value in parsed_formula_contents.items():\n",
    "            deep_models_dict = value[\"deep_models_dict\"]\n",
    "            deep_shapes = value[\"deep_shapes\"]\n",
    "            struct_shapes = value[\"struct_shapes\"]\n",
    "            P = value[\"P\"]\n",
    "            self.single_parameter_sddr_list[key] = Sddr_Single(deep_models_dict, deep_shapes, struct_shapes, P)\n",
    "            \n",
    "            #register the Sddr_Single network\n",
    "            self.add_module(key,self.single_parameter_sddr_list[key])\n",
    "                \n",
    "\n",
    "        #define distributional layer\n",
    "        if family == \"normal\":\n",
    "            self.distribution_layer_type = torch.distributions.normal.Normal\n",
    "        elif family == \"poisson\":\n",
    "            self.distribution_layer_type = torch.distributions.poisson.Poisson\n",
    "    \n",
    "    def _distribution_trafos(self,pred):\n",
    "        #applies the specific transformations to the prediction so they they correspond to the restrictions\n",
    "        #of the parameters\n",
    "        #this is family specific\n",
    "        pred_trafo = dict()\n",
    "        add_const = 1e-8\n",
    "        \n",
    "        family = self.family\n",
    "        if family == \"normal\":\n",
    "            pred_trafo[\"loc\"] = pred[\"loc\"]\n",
    "            pred_trafo[\"scale\"] = add_const + pred[\"scale\"].exp()\n",
    "        elif family == \"poisson\":\n",
    "            pred_trafo[\"rate\"] = add_const + pred[\"rate\"].exp()\n",
    "        \n",
    "        return pred_trafo\n",
    "    \n",
    "    def forward(self,meta_datadict):\n",
    "        \n",
    "        self.regul = 0\n",
    "        pred = dict()\n",
    "        for parameter_name, data_dict  in meta_datadict.items():\n",
    "            sddr_net = self.single_parameter_sddr_list[parameter_name]\n",
    "            pred[parameter_name] = sddr_net(data_dict)\n",
    "            self.regul += sddr_net.get_regularization()*self.regularization_params[parameter_name]\n",
    "            \n",
    "        predicted_parameters = self._distribution_trafos(pred)\n",
    "        \n",
    "        #define distributional layer (takes eta and scale)\n",
    "        self.distribution_layer = self.distribution_layer_type(**predicted_parameters)\n",
    "        \n",
    "        return self.distribution_layer\n",
    "    \n",
    "    def get_loss(self, Y):\n",
    "    \n",
    "#         regul = 0            # move to forward, or we need meta_datadict as input to get_loss\n",
    "#         for parameter_name, data_dict  in meta_datadict.items():\n",
    "#             sddr_net = self.single_parameter_sddr_list[parameter_name]\n",
    "#             regul += sddr_net.get_regularization()*self.regularization_params[parameter_name]\n",
    "        log_loss = -self.distribution_layer.log_prob(Y)\n",
    "        loss = log_loss + self.regul\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        x_csv = pd.read_csv (r'./example_data/simple_gam/X.csv',sep=';',header=None)\n",
    "        y_csv = pd.read_csv (r'./example_data/simple_gam/Y.csv',header=None)\n",
    "        B_csv = pd.read_csv (r'./example_data/simple_gam/B.csv',sep=';',header=None)\n",
    "        \n",
    "        self.struct_data = torch.from_numpy(B_csv.values).float()\n",
    "        self.deep_data = torch.from_numpy(x_csv.values).float()\n",
    "        self.y = torch.from_numpy(y_csv.values).float()\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        struct = self.struct_data[index]\n",
    "        deep = self.deep_data[index]\n",
    "        gt = self.y[index]\n",
    "        \n",
    "        datadict = {\"structured\": struct, \"dm1\": deep}\n",
    "        meta_datadict = dict()\n",
    "        meta_datadict[\"rate\"] = datadict\n",
    "        \n",
    "        return {'meta_datadict': meta_datadict, 'target': gt}        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.deep_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
