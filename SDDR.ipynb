{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from deepregression import Sddr_Single, Sddr\n",
    "from dataset import MyDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# todo\n",
    "\n",
    "sddr single:\n",
    "input to NN cannot be dicts\n",
    "\n",
    "\n",
    "SDDR: may be we make our own get_parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \n",
    "    family = \"poisson\"\n",
    "    \n",
    "    regularization_params = dict()\n",
    "    regularization_params[\"rate\"] = 1.   # already mutiplied in full_P\n",
    "    \n",
    "    deep_models_dict = {}\n",
    "    deep_shapes = {}\n",
    "    struct_shapes = 19\n",
    "    P = pd.read_csv (r'../example_data/simple_gam/full_P.csv',sep=';',header=None).values\n",
    "    #P = pd.read_csv (r'P_gen.csv',sep=';',header=None).values\n",
    "    #P = P[:,1:]\n",
    "    \n",
    "    parsed_formula_contents = dict()\n",
    "    parsed_formula_contents[\"rate\"] = {\"deep_models_dict\": deep_models_dict, \"deep_shapes\": deep_shapes, \"struct_shapes\": struct_shapes, \"P\": P}\n",
    "    \n",
    "    x_path = r'../example_data/simple_gam/X.csv'\n",
    "    y_path = r'../example_data/simple_gam/Y.csv'\n",
    "    b_path = r'B_patsy.csv'\n",
    "    \n",
    "    dataset = MyDataset(x_path, y_path, b_path)\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=1000,\n",
    "    )\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    bignet = Sddr(family, regularization_params, parsed_formula_contents)\n",
    "    bignet = bignet.to(device)\n",
    "    optimizer = optim.RMSprop(bignet.parameters())\n",
    "\n",
    "    bignet.train()\n",
    "    print('Begin training ...')\n",
    "    for epoch in range(1, 2500):\n",
    "\n",
    "        for batch in loader:\n",
    "            target = batch['target'].to(device)\n",
    "            meta_datadict = batch['meta_datadict']          # .to(device) should be improved \n",
    "            meta_datadict['rate']['structured'] = meta_datadict['rate']['structured'].to(device)\n",
    "            meta_datadict['rate']['dm1'] = meta_datadict['rate']['dm1'].to(device)\n",
    "           \n",
    "            optimizer.zero_grad()\n",
    "            output = bignet(meta_datadict)\n",
    "            loss = torch.mean(bignet.get_loss(target))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if epoch % 100 == 0:\n",
    "            print('Train Epoch: {} \\t Loss: {:.6f}'.format(epoch,loss.item()))\n",
    "            \n",
    "    return list(bignet.parameters())[0].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training ...\n",
      "Train Epoch: 100 \t Loss: 237.868607\n",
      "Train Epoch: 200 \t Loss: 2018.443726\n",
      "Train Epoch: 300 \t Loss: 2752.556641\n",
      "Train Epoch: 400 \t Loss: 1445.227295\n",
      "Train Epoch: 500 \t Loss: 1370.811279\n",
      "Train Epoch: 600 \t Loss: 1780.792480\n",
      "Train Epoch: 700 \t Loss: 1838.687988\n",
      "Train Epoch: 800 \t Loss: 1670.657104\n",
      "Train Epoch: 900 \t Loss: 1662.436768\n",
      "Train Epoch: 1000 \t Loss: 1722.786011\n",
      "Train Epoch: 1100 \t Loss: 1723.184692\n",
      "Train Epoch: 1200 \t Loss: 1700.897705\n",
      "Train Epoch: 1300 \t Loss: 1701.970581\n",
      "Train Epoch: 1400 \t Loss: 1710.058716\n",
      "Train Epoch: 1500 \t Loss: 1709.243042\n",
      "Train Epoch: 1600 \t Loss: 1706.331909\n",
      "Train Epoch: 1700 \t Loss: 1706.781250\n",
      "Train Epoch: 1800 \t Loss: 1707.821777\n",
      "Train Epoch: 1900 \t Loss: 1707.607910\n",
      "Train Epoch: 2000 \t Loss: 1707.231079\n",
      "Train Epoch: 2100 \t Loss: 1707.334106\n",
      "Train Epoch: 2200 \t Loss: 1707.465820\n",
      "Train Epoch: 2300 \t Loss: 1707.425049\n",
      "Train Epoch: 2400 \t Loss: 1707.374756\n"
     ]
    }
   ],
   "source": [
    "param = train()    # using adam optimizer can have smooth decreasing loss, using rmsprop the losses converge to a high value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.9548303   4.2193513   2.2116303   0.28337824 -1.0783496  -1.5788293\n",
      "  -1.101281    0.2472983   2.186788    4.2067394   3.1987169   2.5612223\n",
      "   1.9320788   1.2647431   0.6087559  -0.06953965 -0.7047969  -1.3840725\n",
      "  -2.0250263 ]]\n"
     ]
    }
   ],
   "source": [
    "print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 1)\n"
     ]
    }
   ],
   "source": [
    "true_coeff = pd.read_csv (r'../example_data/simple_gam/true_coefficients.csv',sep=';',header=None).values\n",
    "B = pd.read_csv (r'../example_data/simple_gam/B.csv',sep=';',header=None).values\n",
    "#B = pd.read_csv (r'B_gen.csv',sep=';',header=None).values\n",
    "#B=B[:,1:]\n",
    "X = pd.read_csv (r'../example_data/simple_gam/X.csv',sep=';',header=None).values\n",
    "print(true_coeff.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1)\n"
     ]
    }
   ],
   "source": [
    "hatY = np.matmul(B[:,1:10],true_coeff[1:10])\n",
    "print(hatY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_coeff = param\n",
    "pred_coeff = np.transpose(pred_coeff)\n",
    "\n",
    "hatY_pred = np.matmul(B[:,1:10],pred_coeff[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstCov = X[:,0] \n",
    "sortedHatY = [x for _,x in sorted(zip(firstCov,hatY))]\n",
    "sortedHatY_pred = [x for _,x in sorted(zip(firstCov,hatY_pred))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'PySDDR_coefficient')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(np.sort(firstCov), sortedHatY)\n",
    "plt.title('true_coefficient')\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(np.sort(firstCov), sortedHatY_pred)\n",
    "plt.title('PySDDR_coefficient')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test Sddr_Single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deep_shapes = {\"dm1\" : 5, \"dm2\" : 8}\n",
    "\n",
    "net2= nn.Sequential(nn.Linear(10,3),nn.ReLU(), nn.Linear(3,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_models_dict = {\"dm1\" : nn.Linear(10,5, bias = False), \"dm2\" : net2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct_shapes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.eye(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.ones(20,10)\n",
    "datadict = {\"structured\": data, \"dm1\": data, \"dm2\": data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = deepregression.Sddr_Single(deep_models_dict, deep_shapes, struct_shapes, P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226],\n",
       "        [-0.0226]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(datadict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3598]], grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.get_regularization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1935,  0.0301, -0.0123,  0.0357, -0.2134, -0.0730, -0.0048, -0.2697,\n",
      "          0.0231, -0.2892],\n",
      "        [-0.3097, -0.1286,  0.0496, -0.0402,  0.1834,  0.2827,  0.1901, -0.0984,\n",
      "         -0.1785, -0.1594],\n",
      "        [ 0.2092, -0.2141,  0.1104, -0.1351,  0.1407, -0.0386, -0.2448, -0.3022,\n",
      "          0.1182,  0.1253],\n",
      "        [ 0.0958,  0.1131, -0.0343, -0.1154,  0.0705, -0.1790,  0.1225, -0.0100,\n",
      "          0.0172,  0.1540],\n",
      "        [-0.0907, -0.0408, -0.2554,  0.1053,  0.2946,  0.1850, -0.2062, -0.1011,\n",
      "         -0.2434, -0.2904]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0723, -0.3095,  0.2522, -0.2184, -0.3135,  0.1931,  0.0806,  0.1451,\n",
      "         -0.1344, -0.0403],\n",
      "        [ 0.0625, -0.2454,  0.2284,  0.1962,  0.1202, -0.1369, -0.0387, -0.1889,\n",
      "         -0.3157,  0.2815],\n",
      "        [-0.2833,  0.1714, -0.1251, -0.1508,  0.1746,  0.1788,  0.2207,  0.1514,\n",
      "          0.1758, -0.2217]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1996,  0.0521,  0.1826], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1985, -0.1477,  0.0056],\n",
      "        [ 0.5741,  0.1799,  0.2436],\n",
      "        [ 0.4924,  0.5052,  0.1599],\n",
      "        [-0.4921, -0.0860,  0.4233],\n",
      "        [-0.3430, -0.1013, -0.0256],\n",
      "        [ 0.3157,  0.5036, -0.0057],\n",
      "        [-0.2269,  0.0636,  0.4201],\n",
      "        [ 0.4668, -0.5302, -0.3753]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.4091,  0.4470, -0.0806,  0.4474,  0.2930,  0.0864,  0.3742,  0.2597],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.2501,  0.2258,  0.0919, -0.2480,  0.0470,  0.2709, -0.1401,  0.2031,\n",
      "         -0.1980, -0.0251]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 1.7300e-01, -7.1629e-02,  2.4312e-01,  2.2089e-01, -2.6441e-01,\n",
      "         -2.1641e-01,  1.6032e-01,  2.3320e-04, -1.4924e-02,  9.4535e-02,\n",
      "         -8.4762e-02,  1.3740e-01, -8.4525e-02]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in net.parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.6698, -0.1423],\n",
      "        [ 0.5038,  0.0981],\n",
      "        [-0.1744, -0.1339],\n",
      "        [-0.4113,  0.3310],\n",
      "        [-0.4738, -0.2220]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1450,  0.1367,  0.1768,  0.1635, -0.0770,  0.1613, -0.0192,  0.0786,\n",
      "         -0.2005, -0.2166, -0.2112,  0.0377,  0.0462,  0.1035,  0.1268, -0.0238,\n",
      "          0.0126, -0.0916,  0.1823]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1046,  0.2764, -0.3203, -0.0709,  0.2124]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in bignet.parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Sddr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [],
   "source": [
    "family= \"normal\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parsed_formula_contents = dict()\n",
    "parsed_formula_contents[\"loc\"] = {\"deep_models_dict\": deep_models_dict, \"deep_shapes\": deep_shapes, \"struct_shapes\": struct_shapes, \"P\": P}\n",
    "parsed_formula_contents[\"scale\"] = {\"deep_models_dict\": dict(), \"deep_shapes\": dict(), \"struct_shapes\": struct_shapes, \"P\": P}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularization_params = dict()\n",
    "\n",
    "regularization_params[\"loc\"] = 1.\n",
    "regularization_params[\"scale\"] = 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_datadict = dict()\n",
    "\n",
    "'''\n",
    "formulas = dict()\n",
    "\n",
    "formulas['loc'] = '1 + s(x1) + s(x2) + d(x1) + d(x2)'\n",
    "'\n",
    "formulas['scale'] = '1 + s(x)' \n",
    "\n",
    "meta_datadict = parse_formulas(formulas, data)\n",
    "        \n",
    "'''\n",
    "\n",
    "meta_datadict[\"loc\"] = datadict # datadict = {\"structured\": data, \"dm1\": data, \"dm2\": data}\n",
    "meta_datadict[\"scale\"] = {\"structured\": data}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [],
   "source": [
    "bignet = deepregression.Sddr(family, regularization_params, parsed_formula_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loc\n",
      "scale\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Normal(loc: torch.Size([20, 1]), scale: torch.Size([20, 1]))"
      ]
     },
     "execution_count": 843,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bignet(meta_datadict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sddr_Single(\n",
      "  (dm1): Linear(in_features=10, out_features=5, bias=False)\n",
      "  (dm2): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=3, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=3, out_features=8, bias=True)\n",
      "  )\n",
      "  (structured_head): Linear(in_features=10, out_features=1, bias=False)\n",
      "  (deep_head): Linear(in_features=13, out_features=1, bias=False)\n",
      ")\n",
      "Sddr_Single(\n",
      "  (structured_head): Linear(in_features=10, out_features=1, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for i in bignet.children():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0450,  0.3132, -0.2533, -0.0663,  0.1513,  0.1618, -0.1711,  0.1751,\n",
      "          0.2034, -0.1013],\n",
      "        [ 0.1457, -0.1887,  0.1578, -0.0177, -0.0884, -0.2482,  0.1933,  0.1885,\n",
      "          0.1223,  0.1456],\n",
      "        [-0.2872,  0.2873,  0.0221,  0.1267, -0.1926, -0.1228, -0.1013, -0.3115,\n",
      "         -0.1070,  0.3092],\n",
      "        [ 0.2323, -0.0799,  0.2225,  0.0531,  0.0059,  0.1509, -0.1401,  0.2687,\n",
      "          0.1905, -0.2308],\n",
      "        [-0.0035, -0.1833, -0.1211, -0.0225, -0.2246,  0.0049, -0.0644, -0.2636,\n",
      "         -0.1963, -0.2150]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1504,  0.0733, -0.0326,  0.1949, -0.0519, -0.0607, -0.0694,  0.0783,\n",
      "         -0.2417, -0.0261],\n",
      "        [-0.2603, -0.0073,  0.2344, -0.2413, -0.1986, -0.1428, -0.2594,  0.0118,\n",
      "         -0.1722,  0.1692],\n",
      "        [ 0.0141, -0.2903,  0.2476, -0.2810, -0.0929, -0.2952,  0.1316, -0.0939,\n",
      "          0.1434, -0.0977]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.2397, 0.1327, 0.1444], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0546, -0.4211, -0.0831],\n",
      "        [-0.4595, -0.5765,  0.0705],\n",
      "        [-0.3481,  0.2289,  0.0538],\n",
      "        [ 0.4195,  0.3138, -0.3943],\n",
      "        [ 0.0446, -0.0511, -0.4801],\n",
      "        [-0.2535, -0.4461, -0.2677],\n",
      "        [-0.4290,  0.4814, -0.0919],\n",
      "        [-0.1165,  0.1927,  0.2213]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.5256,  0.3756,  0.1480,  0.2058,  0.5054, -0.1609,  0.4523,  0.0451],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1032, -0.2826,  0.2035,  0.0458,  0.1571, -0.0421, -0.2679,  0.3128,\n",
      "         -0.2690,  0.0560]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1785, -0.1413,  0.2162, -0.1403, -0.0686, -0.1385, -0.2135,  0.0126,\n",
      "         -0.0471, -0.1484,  0.2358, -0.1200,  0.1646]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1944, -0.1053, -0.2871, -0.0242, -0.0027,  0.2059,  0.0305,  0.2846,\n",
      "          0.0894, -0.0680]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in bignet.parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = torch.ones([20,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1])"
      ]
     },
     "execution_count": 847,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = bignet.get_loss(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.mean().backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing for dictionary as input to neural network module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class testnn(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(testnn, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.weights = nn.Parameter(torch.ones(784, 10) )\n",
    "        self.bias = nn.Parameter(torch.zeros(10))\n",
    "\n",
    "    def forward(self, xa):\n",
    "        #xa = datadict[\"a\"]\n",
    "        #xb = datadict[\"b\"]\n",
    "        out = xa @ self.weights + xa @ self.weights + self.bias\n",
    "        return out\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "testnn_obj = testnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.ones([784,10]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = testnn_obj(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_list = []\n",
    "for i in testnn_obj.parameters():\n",
    "    param_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss  = (out-100)**2\n",
    "\n",
    "loss.mean().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[587.2000, 587.2000, 587.2000,  ..., 587.2000, 587.2000, 587.2000],\n",
       "        [587.2000, 587.2000, 587.2000,  ..., 587.2000, 587.2000, 587.2000],\n",
       "        [587.2000, 587.2000, 587.2000,  ..., 587.2000, 587.2000, 587.2000],\n",
       "        ...,\n",
       "        [587.2000, 587.2000, 587.2000,  ..., 587.2000, 587.2000, 587.2000],\n",
       "        [587.2000, 587.2000, 587.2000,  ..., 587.2000, 587.2000, 587.2000],\n",
       "        [587.2000, 587.2000, 587.2000,  ..., 587.2000, 587.2000, 587.2000]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_list[0].grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "testnn_obj.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This code can be found in deepregression.py and dataset.py so should not be used here so we only make changes to one code and don't get confused. Remove after checking with others that it is exact duplicate ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Sddr_Single(nn.Module):\n",
    "    \n",
    "    def __init__(self, deep_models_dict, deep_shapes, struct_shapes, P):\n",
    "        \"\"\"\n",
    "        deep_models_dict: dictionary where key are names of deep models and values are objects that define the deep models\n",
    "        struct_shapes: number of structural features\n",
    "        P: numpy matrix for the smoothing regularization (with added zero matrix in the beginning for the linear part)\n",
    "        \n",
    "        \"\"\"\n",
    "        super(Sddr_Single, self).__init__()\n",
    "        self.P = P\n",
    "        self.deep_models_dict = deep_models_dict\n",
    "        \n",
    "        #register external neural networks\n",
    "        for key, value in deep_models_dict.items():\n",
    "            self.add_module(key,value)\n",
    "        \n",
    "        \n",
    "        self.structured_head = nn.Linear(struct_shapes,1, bias = False)\n",
    "        \n",
    "        if len(deep_models_dict) != 0:\n",
    "            output_size_of_deep_models  = sum([deep_shapes[key] for key in deep_shapes.keys()])\n",
    "            self.deep_head = nn.Linear(output_size_of_deep_models,1, bias = False)\n",
    "            self._deep_models_exist = True\n",
    "        else:\n",
    "            self._deep_models_exist = False\n",
    "        \n",
    "              \n",
    "        \n",
    "    def _orthog_layer(self, Q, Uhat):\n",
    "        \"\"\"\n",
    "        Utilde = Uhat - QQTUhat\n",
    "        \"\"\"\n",
    "        print(Q)\n",
    "        print(Q.T)\n",
    "        Projection_Matrix = Q @ Q.T\n",
    "        print(Projection_Matrix)\n",
    "        Utilde = Uhat - Projection_Matrix @ Uhat\n",
    "        \n",
    "        return Utilde\n",
    "    \n",
    "    \n",
    "    def forward(self, datadict):\n",
    "        \"\"\"Comment 6.8.2020 We checked that we can actually have a dictionary as an input here. that should work fine\"\"\"\n",
    "        \n",
    "        X = datadict[\"structured\"]\n",
    "        \n",
    "        if self._deep_models_exist:\n",
    "            Q, R = torch.qr(X)\n",
    "\n",
    "            Uhat_list = []\n",
    "            for key in self.deep_models_dict.keys(): #assume that the input for the NN has the name of the NN as key\n",
    "                net = self.deep_models_dict[key]\n",
    "                Uhat_list.append(net(datadict[key]))\n",
    "            \n",
    "            Uhat = torch.cat(Uhat_list, dim = 1) #concatenate the outputs of the deep NNs\n",
    "\n",
    "            Utilde = self._orthog_layer(Q, Uhat)\n",
    "            \n",
    "            deep_pred = self.deep_head(Utilde)\n",
    "        else:\n",
    "            deep_pred = 0\n",
    "        \n",
    "        structured_pred = self.structured_head(X)\n",
    "        \n",
    "        pred = structured_pred + deep_pred\n",
    "        \n",
    "        return pred\n",
    "    \n",
    "    def get_regularization(self):\n",
    "        P = torch.from_numpy(self.P).float() # should have shape struct_shapes x struct_shapes, numpy array\n",
    "        weights = self.structured_head.weight #should have shape 1 x struct_shapes\n",
    "        \n",
    "        \n",
    "        regularization = weights @ P @ weights.T\n",
    "        \n",
    "        return regularization\n",
    "        \n",
    "        \n",
    "        \n",
    "class Sddr(nn.Module):\n",
    "    \n",
    "    def __init__(self, family, regularization_params, parsed_formula_contents):\n",
    "        \"\"\"\n",
    "        family: string e.g. \"gaussian\", \"binomial\"...\n",
    "        regularization_params: smoothing parameters\n",
    "        parsed_formula_contents: dictionary with keys being parameters of the distribution, e.g. \"eta\" and \"scale\"\n",
    "        and values being dicts with keys deep_models_dict, struct_shapes and P (as used in Sddr_Single)\n",
    "        \"\"\"\n",
    "        super(Sddr, self).__init__()\n",
    "        self.family = family\n",
    "        self.regularization_params = regularization_params\n",
    "        self.parameter_names = parsed_formula_contents.keys\n",
    "        self.single_parameter_sddr_list = dict()\n",
    "        for key, value in parsed_formula_contents.items():\n",
    "            deep_models_dict = value[\"deep_models_dict\"]\n",
    "            deep_shapes = value[\"deep_shapes\"]\n",
    "            struct_shapes = value[\"struct_shapes\"]\n",
    "            P = value[\"P\"]\n",
    "            self.single_parameter_sddr_list[key] = Sddr_Single(deep_models_dict, deep_shapes, struct_shapes, P)\n",
    "            \n",
    "            #register the Sddr_Single network\n",
    "            self.add_module(key,self.single_parameter_sddr_list[key])\n",
    "                \n",
    "\n",
    "        #define distributional layer\n",
    "        if family == \"normal\":\n",
    "            self.distribution_layer_type = torch.distributions.normal.Normal\n",
    "        elif family == \"poisson\":\n",
    "            self.distribution_layer_type = torch.distributions.poisson.Poisson\n",
    "    \n",
    "    def _distribution_trafos(self,pred):\n",
    "        #applies the specific transformations to the prediction so they they correspond to the restrictions\n",
    "        #of the parameters\n",
    "        #this is family specific\n",
    "        pred_trafo = dict()\n",
    "        add_const = 1e-8\n",
    "        \n",
    "        family = self.family\n",
    "        if family == \"normal\":\n",
    "            pred_trafo[\"loc\"] = pred[\"loc\"]\n",
    "            pred_trafo[\"scale\"] = add_const + pred[\"scale\"].exp()\n",
    "        elif family == \"poisson\":\n",
    "            pred_trafo[\"rate\"] = add_const + pred[\"rate\"].exp()\n",
    "        \n",
    "        return pred_trafo\n",
    "    \n",
    "    def forward(self,meta_datadict):\n",
    "        \n",
    "        self.regul = 0\n",
    "        pred = dict()\n",
    "        for parameter_name, data_dict  in meta_datadict.items():\n",
    "            sddr_net = self.single_parameter_sddr_list[parameter_name]\n",
    "            pred[parameter_name] = sddr_net(data_dict)\n",
    "            self.regul += sddr_net.get_regularization()*self.regularization_params[parameter_name]\n",
    "            \n",
    "        predicted_parameters = self._distribution_trafos(pred)\n",
    "        \n",
    "        #define distributional layer (takes eta and scale)\n",
    "        self.distribution_layer = self.distribution_layer_type(**predicted_parameters)\n",
    "        \n",
    "        return self.distribution_layer\n",
    "    \n",
    "    def get_loss(self, Y):\n",
    "    \n",
    "#         regul = 0            # move to forward, or we need meta_datadict as input to get_loss\n",
    "#         for parameter_name, data_dict  in meta_datadict.items():\n",
    "#             sddr_net = self.single_parameter_sddr_list[parameter_name]\n",
    "#             regul += sddr_net.get_regularization()*self.regularization_params[parameter_name]\n",
    "        log_loss = -self.distribution_layer.log_prob(Y)\n",
    "        loss = log_loss + self.regul\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        x_csv = pd.read_csv (r'./example_data/simple_gam/X.csv',sep=';',header=None)\n",
    "        y_csv = pd.read_csv (r'./example_data/simple_gam/Y.csv',header=None)\n",
    "        B_csv = pd.read_csv (r'./example_data/simple_gam/B.csv',sep=';',header=None)\n",
    "        \n",
    "        self.struct_data = torch.from_numpy(B_csv.values).float()\n",
    "        self.deep_data = torch.from_numpy(x_csv.values).float()\n",
    "        self.y = torch.from_numpy(y_csv.values).float()\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        struct = self.struct_data[index]\n",
    "        deep = self.deep_data[index]\n",
    "        gt = self.y[index]\n",
    "        \n",
    "        datadict = {\"structured\": struct, \"dm1\": deep}\n",
    "        meta_datadict = dict()\n",
    "        meta_datadict[\"rate\"] = datadict\n",
    "        \n",
    "        return {'meta_datadict': meta_datadict, 'target': gt}        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.deep_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
