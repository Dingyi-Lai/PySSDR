{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch import nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# todo\n",
    "\n",
    "sddr single:\n",
    "input to NN cannot be dicts\n",
    "\n",
    "\n",
    "SDDR: may be we make our own get_parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Sddr_Single(nn.Module):\n",
    "    \n",
    "    def __init__(self, deep_models_dict, deep_shapes, struct_shapes, P):\n",
    "        \"\"\"\n",
    "        deep_models_dict: dictionary where key are names of deep models and values are objects that define the deep models\n",
    "        struct_shapes: number of structural features\n",
    "        P: numpy matrix for the smoothing regularization (with added zero matrix in the beginning for the linear part)\n",
    "        \n",
    "        \"\"\"\n",
    "        super(Sddr_Single, self).__init__()\n",
    "        self.P = P\n",
    "        self.deep_models_dict = deep_models_dict\n",
    "        \n",
    "        #register external neural networks\n",
    "        for key, value in deep_models_dict.items():\n",
    "            self.add_module(key,value)\n",
    "        \n",
    "        \n",
    "        self.structured_head = nn.Linear(struct_shapes,1, bias = False)\n",
    "        \n",
    "        if len(deep_models_dict) != 0:\n",
    "            output_size_of_deep_models  = sum([deep_shapes[key] for key in deep_shapes.keys()])\n",
    "            self.deep_head = nn.Linear(output_size_of_deep_models,1, bias = False)\n",
    "            self._deep_models_exist = True\n",
    "        else:\n",
    "            self._deep_models_exist = False\n",
    "        \n",
    "              \n",
    "        \n",
    "    def _orthog_layer(self, Q, Uhat):\n",
    "        \"\"\"\n",
    "        Utilde = Uhat - QQTUhat\n",
    "        \"\"\"\n",
    "        Projection_Matrix = Q @ Q.T\n",
    "        Utilde = Uhat - Projection_Matrix @ Uhat\n",
    "        \n",
    "        return Utilde\n",
    "    \n",
    "    \n",
    "    def forward(self, datadict):\n",
    "        \"\"\"Comment 6.8.2020 We checked that we can actually have a dictionary as an input here. that should work fine\"\"\"\n",
    "        \n",
    "        X = datadict[\"structured\"]\n",
    "        \n",
    "        if self._deep_models_exist:\n",
    "            Q, R = torch.qr(X)\n",
    "\n",
    "            Uhat_list = []\n",
    "            for key in self.deep_models_dict.keys(): #assume that the input for the NN has the name of the NN as key\n",
    "                net = self.deep_models_dict[key]\n",
    "                Uhat_list.append(net(datadict[key]))\n",
    "\n",
    "            Uhat = torch.cat(Uhat_list, dim = 1) #concatenate the outputs of the deep NNs\n",
    "\n",
    "            Utilde = self._orthog_layer(Q, Uhat)\n",
    "            \n",
    "            deep_pred = self.deep_head(Utilde)\n",
    "        else:\n",
    "            deep_pred = 0\n",
    "        \n",
    "        structured_pred = self.structured_head(X)\n",
    "        \n",
    "        pred = structured_pred + deep_pred\n",
    "        \n",
    "        return pred\n",
    "    \n",
    "    def get_regularization(self):\n",
    "        P = torch.from_numpy(self.P).float() # should have shape struct_shapes x struct_shapes, numpy array\n",
    "        weights = self.structured_head.weight #should have shape 1 x struct_shapes\n",
    "        \n",
    "        \n",
    "        regularization = weights @ P @ weights.T\n",
    "        \n",
    "        return regularization\n",
    "        \n",
    "        \n",
    "        \n",
    "class Sddr(nn.Module):\n",
    "    \n",
    "    def __init__(self, family, regularization_params, parsed_formula_contents):\n",
    "        \"\"\"\n",
    "        family: string e.g. \"gaussian\", \"binomial\"...\n",
    "        regularization_params: smoothing parameters\n",
    "        parsed_formula_contents: dictionary with keys being parameters of the distribution, e.g. \"eta\" and \"scale\"\n",
    "        and values being dicts with keys deep_models_dict, struct_shapes and P (as used in Sddr_Single)\n",
    "        \"\"\"\n",
    "        super(Sddr, self).__init__()\n",
    "        self.family = family\n",
    "        self.regularization_params = regularization_params\n",
    "        self.parameter_names = parsed_formula_contents.keys\n",
    "        self.single_parameter_sddr_list = dict()\n",
    "        for key, value in parsed_formula_contents.items():\n",
    "            deep_models_dict = value[\"deep_models_dict\"]\n",
    "            deep_shapes = value[\"deep_shapes\"]\n",
    "            struct_shapes = value[\"struct_shapes\"]\n",
    "            P = value[\"P\"]\n",
    "            self.single_parameter_sddr_list[key] = Sddr_Single(deep_models_dict, deep_shapes, struct_shapes, P)\n",
    "            \n",
    "            #register the Sddr_Single network\n",
    "            self.add_module(key,self.single_parameter_sddr_list[key])\n",
    "                \n",
    "\n",
    "        #define distributional layer\n",
    "        if family == \"normal\":\n",
    "            self.distribution_layer_type = torch.distributions.normal.Normal\n",
    "    \n",
    "    def _distribution_trafos(self,pred):\n",
    "        #applies the specific transformations to the prediction so they they correspond to the restrictions\n",
    "        #of the parameters\n",
    "        #this is family specific\n",
    "        pred_trafo = dict()\n",
    "        add_const = 1e-8\n",
    "        \n",
    "        family = self.family\n",
    "        if family == \"normal\":\n",
    "            pred_trafo[\"loc\"] = pred[\"loc\"]\n",
    "            pred_trafo[\"scale\"] = add_const + pred[\"scale\"].exp()\n",
    "        \n",
    "        return pred_trafo\n",
    "    \n",
    "    def forward(self,meta_datadict):\n",
    "        \n",
    "        pred = dict()\n",
    "        for parameter_name, data_dict  in meta_datadict.items():\n",
    "            print(parameter_name)\n",
    "            sddr_net = self.single_parameter_sddr_list[parameter_name]\n",
    "            pred[parameter_name] = sddr_net(data_dict)\n",
    "            \n",
    "        predicted_parameters = self._distribution_trafos(pred)\n",
    "        \n",
    "        #define distributional layer (takes eta and scale)\n",
    "        self.distribution_layer = self.distribution_layer_type(**predicted_parameters)\n",
    "        \n",
    "        return self.distribution_layer\n",
    "    \n",
    "    def get_loss(self, Y):\n",
    "    \n",
    "        regul = 0\n",
    "        for parameter_name, data_dict  in meta_datadict.items():\n",
    "            sddr_net = self.single_parameter_sddr_list[parameter_name]\n",
    "            regul += sddr_net.get_regularization()*self.regularization_params[parameter_name]\n",
    "        log_loss = -self.distribution_layer.log_prob(Y)\n",
    "        loss = log_loss + regul\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test Sddr_Single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deep_shapes = {\"dm1\" : 5, \"dm2\" : 8}\n",
    "\n",
    "net2= nn.Sequential(nn.Linear(10,3),nn.ReLU(), nn.Linear(3,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_models_dict = {\"dm1\" : nn.Linear(10,5, bias = False), \"dm2\" : net2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct_shapes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.eye(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.ones(20,10)\n",
    "datadict = {\"structured\": data, \"dm1\": data, \"dm2\": data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Sddr_Single(deep_models_dict, deep_shapes, struct_shapes, P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0535],\n",
       "        [-0.0535],\n",
       "        [-0.0535],\n",
       "        [-0.0535],\n",
       "        [-0.0535],\n",
       "        [-0.0535],\n",
       "        [-0.0535],\n",
       "        [-0.0535],\n",
       "        [-0.0535],\n",
       "        [-0.0535],\n",
       "        [-0.0535],\n",
       "        [-0.0535],\n",
       "        [-0.0535],\n",
       "        [-0.0535],\n",
       "        [-0.0535],\n",
       "        [-0.0535],\n",
       "        [-0.0535],\n",
       "        [-0.0535],\n",
       "        [-0.0535],\n",
       "        [-0.0535]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 834,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(datadict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4237]], grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 835,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.get_regularization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0450,  0.3132, -0.2533, -0.0663,  0.1513,  0.1618, -0.1711,  0.1751,\n",
      "          0.2034, -0.1013],\n",
      "        [ 0.1457, -0.1887,  0.1578, -0.0177, -0.0884, -0.2482,  0.1933,  0.1885,\n",
      "          0.1223,  0.1456],\n",
      "        [-0.2872,  0.2873,  0.0221,  0.1267, -0.1926, -0.1228, -0.1013, -0.3115,\n",
      "         -0.1070,  0.3092],\n",
      "        [ 0.2323, -0.0799,  0.2225,  0.0531,  0.0059,  0.1509, -0.1401,  0.2687,\n",
      "          0.1905, -0.2308],\n",
      "        [-0.0035, -0.1833, -0.1211, -0.0225, -0.2246,  0.0049, -0.0644, -0.2636,\n",
      "         -0.1963, -0.2150]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1504,  0.0733, -0.0326,  0.1949, -0.0519, -0.0607, -0.0694,  0.0783,\n",
      "         -0.2417, -0.0261],\n",
      "        [-0.2603, -0.0073,  0.2344, -0.2413, -0.1986, -0.1428, -0.2594,  0.0118,\n",
      "         -0.1722,  0.1692],\n",
      "        [ 0.0141, -0.2903,  0.2476, -0.2810, -0.0929, -0.2952,  0.1316, -0.0939,\n",
      "          0.1434, -0.0977]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.2397, 0.1327, 0.1444], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0546, -0.4211, -0.0831],\n",
      "        [-0.4595, -0.5765,  0.0705],\n",
      "        [-0.3481,  0.2289,  0.0538],\n",
      "        [ 0.4195,  0.3138, -0.3943],\n",
      "        [ 0.0446, -0.0511, -0.4801],\n",
      "        [-0.2535, -0.4461, -0.2677],\n",
      "        [-0.4290,  0.4814, -0.0919],\n",
      "        [-0.1165,  0.1927,  0.2213]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.5256,  0.3756,  0.1480,  0.2058,  0.5054, -0.1609,  0.4523,  0.0451],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1689,  0.1397, -0.2754, -0.0093,  0.2364,  0.2882, -0.1848, -0.1166,\n",
      "         -0.2184,  0.2557]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.2170, -0.1446,  0.0003,  0.0607,  0.0386,  0.0032, -0.0363,  0.1704,\n",
      "          0.0879, -0.2120,  0.0019,  0.0112,  0.0591]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in net.parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=10, out_features=5, bias=False)\n",
      "Sequential(\n",
      "  (0): Linear(in_features=10, out_features=3, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=3, out_features=8, bias=True)\n",
      ")\n",
      "Linear(in_features=10, out_features=1, bias=False)\n",
      "Linear(in_features=13, out_features=1, bias=False)\n"
     ]
    }
   ],
   "source": [
    "for name in net.children():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Sddr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [],
   "source": [
    "family= \"normal\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_formula_contents = dict()\n",
    "parsed_formula_contents[\"loc\"] = {\"deep_models_dict\": deep_models_dict, \"deep_shapes\": deep_shapes, \"struct_shapes\": struct_shapes, \"P\": P}\n",
    "parsed_formula_contents[\"scale\"] = {\"deep_models_dict\": dict(), \"deep_shapes\": dict(), \"struct_shapes\": struct_shapes, \"P\": P}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularization_params = dict()\n",
    "\n",
    "regularization_params[\"loc\"] = 1.\n",
    "regularization_params[\"scale\"] = 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_datadict = dict()\n",
    "\n",
    "meta_datadict[\"loc\"] = datadict\n",
    "meta_datadict[\"scale\"] = {\"structured\": data}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [],
   "source": [
    "bignet = Sddr(family, regularization_params, parsed_formula_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loc\n",
      "scale\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Normal(loc: torch.Size([20, 1]), scale: torch.Size([20, 1]))"
      ]
     },
     "execution_count": 843,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bignet(meta_datadict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sddr_Single(\n",
      "  (dm1): Linear(in_features=10, out_features=5, bias=False)\n",
      "  (dm2): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=3, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=3, out_features=8, bias=True)\n",
      "  )\n",
      "  (structured_head): Linear(in_features=10, out_features=1, bias=False)\n",
      "  (deep_head): Linear(in_features=13, out_features=1, bias=False)\n",
      ")\n",
      "Sddr_Single(\n",
      "  (structured_head): Linear(in_features=10, out_features=1, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for i in bignet.children():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0450,  0.3132, -0.2533, -0.0663,  0.1513,  0.1618, -0.1711,  0.1751,\n",
      "          0.2034, -0.1013],\n",
      "        [ 0.1457, -0.1887,  0.1578, -0.0177, -0.0884, -0.2482,  0.1933,  0.1885,\n",
      "          0.1223,  0.1456],\n",
      "        [-0.2872,  0.2873,  0.0221,  0.1267, -0.1926, -0.1228, -0.1013, -0.3115,\n",
      "         -0.1070,  0.3092],\n",
      "        [ 0.2323, -0.0799,  0.2225,  0.0531,  0.0059,  0.1509, -0.1401,  0.2687,\n",
      "          0.1905, -0.2308],\n",
      "        [-0.0035, -0.1833, -0.1211, -0.0225, -0.2246,  0.0049, -0.0644, -0.2636,\n",
      "         -0.1963, -0.2150]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1504,  0.0733, -0.0326,  0.1949, -0.0519, -0.0607, -0.0694,  0.0783,\n",
      "         -0.2417, -0.0261],\n",
      "        [-0.2603, -0.0073,  0.2344, -0.2413, -0.1986, -0.1428, -0.2594,  0.0118,\n",
      "         -0.1722,  0.1692],\n",
      "        [ 0.0141, -0.2903,  0.2476, -0.2810, -0.0929, -0.2952,  0.1316, -0.0939,\n",
      "          0.1434, -0.0977]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.2397, 0.1327, 0.1444], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0546, -0.4211, -0.0831],\n",
      "        [-0.4595, -0.5765,  0.0705],\n",
      "        [-0.3481,  0.2289,  0.0538],\n",
      "        [ 0.4195,  0.3138, -0.3943],\n",
      "        [ 0.0446, -0.0511, -0.4801],\n",
      "        [-0.2535, -0.4461, -0.2677],\n",
      "        [-0.4290,  0.4814, -0.0919],\n",
      "        [-0.1165,  0.1927,  0.2213]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.5256,  0.3756,  0.1480,  0.2058,  0.5054, -0.1609,  0.4523,  0.0451],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1032, -0.2826,  0.2035,  0.0458,  0.1571, -0.0421, -0.2679,  0.3128,\n",
      "         -0.2690,  0.0560]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1785, -0.1413,  0.2162, -0.1403, -0.0686, -0.1385, -0.2135,  0.0126,\n",
      "         -0.0471, -0.1484,  0.2358, -0.1200,  0.1646]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1944, -0.1053, -0.2871, -0.0242, -0.0027,  0.2059,  0.0305,  0.2846,\n",
      "          0.0894, -0.0680]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in bignet.parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = torch.ones([20,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1])"
      ]
     },
     "execution_count": 847,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = bignet.get_loss(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.mean().backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing for dictionary as input to neural network module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class testnn(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(testnn, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.weights = nn.Parameter(torch.ones(784, 10) )\n",
    "        self.bias = nn.Parameter(torch.zeros(10))\n",
    "\n",
    "    def forward(self, xa):\n",
    "        #xa = datadict[\"a\"]\n",
    "        #xb = datadict[\"b\"]\n",
    "        out = xa @ self.weights + xa @ self.weights + self.bias\n",
    "        return out\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "testnn_obj = testnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.ones([784,10]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = testnn_obj(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_list = []\n",
    "for i in testnn_obj.parameters():\n",
    "    param_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss  = (out-100)**2\n",
    "\n",
    "loss.mean().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[587.2000, 587.2000, 587.2000,  ..., 587.2000, 587.2000, 587.2000],\n",
       "        [587.2000, 587.2000, 587.2000,  ..., 587.2000, 587.2000, 587.2000],\n",
       "        [587.2000, 587.2000, 587.2000,  ..., 587.2000, 587.2000, 587.2000],\n",
       "        ...,\n",
       "        [587.2000, 587.2000, 587.2000,  ..., 587.2000, 587.2000, 587.2000],\n",
       "        [587.2000, 587.2000, 587.2000,  ..., 587.2000, 587.2000, 587.2000],\n",
       "        [587.2000, 587.2000, 587.2000,  ..., 587.2000, 587.2000, 587.2000]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_list[0].grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "testnn_obj.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TorchKernel",
   "language": "python",
   "name": "torchkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
